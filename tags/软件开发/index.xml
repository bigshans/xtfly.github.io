<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>软件开发 on 蘭陵N散記</title>
    <link>http://lanlingzi.cn/tags/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/index.xml</link>
    <description>Recent content in 软件开发 on 蘭陵N散記</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <atom:link href="http://lanlingzi.cn/tags/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Design for Failure</title>
      <link>http://lanlingzi.cn/post/technical/2017/0216_dff/</link>
      <pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2017/0216_dff/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://lanlingzi.cn/images/dff/dff.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;

&lt;p&gt;故有的思维会影响创新，在传统的软件设计考虑高可靠性，主要方法论是”防“，处处保护，让系统的每一处能长时间运行，不中断地提供服务。事实上电信级高可用性（HA）也只能宣称达到5个9，这意味着一年也就只有5分半钟的中断时间。但每增加一个9却实施成本非常地高，有些是建立在硬件可靠基础之上，并且不少是实验数据或理论上支持。传统的思维认识，在泥沙上建房子不可靠的。但软件架构设计，即完全不一样，在不可靠的基础设施上构建上可靠的系统，那才是真正NB的。&lt;/p&gt;

&lt;p&gt;依稀记得云计算刚出来时，大家都是持怀疑态度：性能下降的虚拟化技术、安全不可控的网络、变化复杂的资源管理，在其上如何构建可靠稳定的软件系统？事实上，Netflix完全基于AWS云基础设施，认为都有可能发生任何的故障（Failure），更何况资源也不掌握在自己手上。Netflix基于&lt;code&gt;Design for Failure&lt;/code&gt;理念却构建出用户无感知的高可用系统，支撑他的业务飞速发展。事实上，故障无所不在，尤其是在云计算环境中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;资源层次：电能失效，整个数据中心不可用；部分计算失效，网络不通，存储IO高等&lt;/li&gt;
&lt;li&gt;应用层次：资源泄露；软件Bug；系统处理能力不足等&lt;/li&gt;
&lt;li&gt;数据层次：数据丢失；数据不一致等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;概念解读&#34;&gt;概念解读&lt;/h2&gt;

&lt;p&gt;既然故障不可避免，何不让故障尽早的暴露，尽快的恢复。设计时针对故障场景而设计，一切假定在故障失效下如何处理，局部的失效不影响整体的可用性。这就是&lt;code&gt;Design for Failure&lt;/code&gt;的核心理念。这个设计理念其实也跟人类社会很像：一个人的细胞代谢，只要有新的细胞补上就行；一个组织中，高度细分工作，几个人的离开，不影响整体的运转。&lt;code&gt;Design for Failure&lt;/code&gt;不仅仅是高可用性设计，而是一种新的设计理念，有别于传统，通过单点的可靠性达到整体的高可用性。以Netflix公布的数据来看，每个EC2实例平均生命周期只有36个小时，每个单点不断地重生，才能达到整体的高可用性。其关键实施要点总结如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;容错：当系统中出现了各种故障时，系统能够自动隔离故障而不影响系统对外的服务质量。&lt;/li&gt;
&lt;li&gt;冗余：提供系统冗余配置，当系统发生故障时，冗余的快速介入并承担已发生故障的工作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以一个运行在云环境中的应用为例，&lt;code&gt;Design for Failure&lt;/code&gt;理念需要按如下步骤来考虑：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个应用程序组件必须部署在冗余的云组件/服务上，有很少或没有失败的共同点，即不存在单点故障；&lt;/li&gt;
&lt;li&gt;每个应用组件必须对基础设施不作任何假设，它必须能够在不停机的情况下适应基础设施的变化；&lt;/li&gt;
&lt;li&gt;每个应用程序组件应该是分区容忍，换句话说，它应该能够生存的网络延迟（或通信损失）的节点上；&lt;/li&gt;
&lt;li&gt;借助于自动化工具，必须能编排应用程序，以便响应失败或其他基础设施的变化等等。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;案例分析&#34;&gt;案例分析&lt;/h2&gt;

&lt;p&gt;一个单点的故障，我们可能针对性地很容易解决，这可能是头痛医头的做法。但一个系统软件往往没有那么简单，举例来说，一个汽车生产线，生产不同的汽车，需要使用不同的零件，如果某个零件因为种种原因无法使用，那么就会造成整台车无法装配，陷入等待零件的状态，直到零件到位，才能继续组装。 此时如果有很多个车型都需要这个零件，那么整个工厂都将陷入等待的状态，导致所有生产都陷入瘫痪。一个零件的波及范围不断扩大。这就是我们常说的&lt;code&gt;雪崩效应&lt;/code&gt;。所以我们非常有必要分析系统中的各种依赖关系。不同的层次来&lt;code&gt;Design for Failure&lt;/code&gt;，不同的技术组合来解决问题。&lt;/p&gt;

&lt;p&gt;以Netflix的系统架构来简单分析一下，看它是如何分层解决问题的：&lt;/p&gt;

&lt;h3 id=&#34;接入层&#34;&gt;接入层：&lt;/h3&gt;

&lt;h4 id=&#34;aws-elb&#34;&gt;AWS ELB&lt;/h4&gt;

&lt;p&gt;典型的部署架构都是多地区（Region）、多可用区（Zone）的部署。负责四层负载分发，支持跨Region调用，它解决是当一个Region不可用的分发。&lt;/p&gt;

&lt;h4 id=&#34;zuul&#34;&gt;Zuul&lt;/h4&gt;

&lt;p&gt;Zuul负责七层分发，提供动态路由，监控，弹性，安全等。Zuul可以通过加载动态过滤机制，从而实现以下各项功能：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;验证与安全保障: 识别面向各类资源的验证要求并拒绝那些与要求不符的请求；&lt;/li&gt;
&lt;li&gt;审查与监控: 在边缘位置追踪有意义数据及统计结果，从而为我们带来准确的生产状态结论；&lt;/li&gt;
&lt;li&gt;动态路由: 以动态方式根据需要将请求路由至不同后端集群处；&lt;/li&gt;
&lt;li&gt;压力测试: 逐渐增加指向集群的负载流量，从而计算性能水平；&lt;/li&gt;
&lt;li&gt;负载分配: 为每一种负载类型分配对应容量，并弃用超出限定值的请求；&lt;/li&gt;
&lt;li&gt;静态响应处理: 在边缘位置直接建立部分响应，从而避免其流入内部集群；&lt;/li&gt;
&lt;li&gt;多区域弹性: 跨越AWS区域进行请求路由，旨在实现ELB使用多样化并保证边缘位置与使用者尽可能接近；&lt;/li&gt;
&lt;li&gt;金丝雀测试：金丝雀版本实现精确路由；&lt;/li&gt;
&lt;li&gt;故障注入：结合故障注入工具，从前端自动注入故障；&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;服务层&#34;&gt;服务层&lt;/h3&gt;

&lt;h4 id=&#34;eureka&#34;&gt;Eureka&lt;/h4&gt;

&lt;p&gt;Eureka为所有Netflix服务提供服务注册集中管理，当然它也是可以分Zone分Region集群部署的。它与Zookeeper不同是：Zookeeper侧重于CP，而Eureka侧重于AP；服务注册信息支持跨Region的复制。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Eureka服务端用作服务注册，提供服务实例信息注册与同步；&lt;/li&gt;
&lt;li&gt;Eureka客户端用用服务发现，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;ribbon&#34;&gt;Ribbon&lt;/h4&gt;

&lt;p&gt;由于Eureka是非强一致性，服务实例状态并非是实时性，服务调用可能失败或超时。所以Ribbon作为客户端组，配合Eureka一起使用，作为服务路由均衡的补充。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ribbon客户端提供一系列完善的配置选项，比如连接超时、重试、重试算法等，&lt;/li&gt;
&lt;li&gt;Ribbon内置可插拔、可定制的负载均衡组件，支持多种均衡策略：简单轮询负载均衡；加权响应时间负载均衡；区域感知轮询负载均衡；机负载均衡。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在选择服务器时，该负载均衡器会采取如下步骤：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;负载均衡器会检查、计算所有可用区域的状态。如果某个区域中平均每个服务器的活跃请求已经达到配置的阈值，该区域将从活跃服务器列表中排除。如果多于一个区域已经到达阈值，平均每服务器拥有最多活跃请求的区域将被排除。&lt;/li&gt;
&lt;li&gt;最差的区域被排除后，从剩下的区域中，将按照服务器实例数的概率抽样法选择一个区域。&lt;/li&gt;
&lt;li&gt;从选定区域中，将会根据给定负载均衡策略规则返回一个服务器。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;hystrix&#34;&gt;Hystrix&lt;/h4&gt;

&lt;p&gt;Hystrix提供分布式系统使用，提供延迟和容错功能，隔离远程系统、访问和第三方程序库的访问点，防止级联失败，保证复杂的分布系统在面临不可避免的失败时，仍能有其弹性。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;隔离模式：简单说就是为每个依赖调用分配一个小的线程池，如果线程池已满调用将被立即拒绝，默认不采用排队，加速失败判定时间。&lt;/li&gt;
&lt;li&gt;熔断模式：目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上述两种模式的实施，是服务速错，服务降级的基础。&lt;/p&gt;

&lt;h3 id=&#34;数据层&#34;&gt;数据层&lt;/h3&gt;

&lt;h4 id=&#34;evcache&#34;&gt;EVCache&lt;/h4&gt;

&lt;p&gt;VCache是一个数据缓存服务，专门为Netflix的微服务提供低延迟，高可靠性的缓存解决方案。它是基于memcached的内存存储，专门为云计算优化，适合对强一致性没有必须要求的场合。它不需要处理全局锁，群体读写，事务更新，部分提交和回滚，和其他一些分布式一致性的复杂设计。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;跨区可用：一个地区的的会员切换到另外一个地区，会在新的地区缓存中没有老地区的数据，称为cold cache，缓存会保存着重新计算需要的临时数据，这些数据如果从持久层存储获得将会非常昂贵，所以这种数据写入到本地缓存，并必须复制到所有地区的缓存中，以便服务于各个地区会员使用。&lt;/li&gt;
&lt;li&gt;复制延迟：在跨区域复制变慢的情况下，不会影响性能和本地缓存的可靠性，所有复制都是异步的，复制系统能够在不影响本地缓存操作情况下悄悄地短时间中断。不需要一个完美的复制系统，可以接受EVcache一定限度的延迟和不一致，只要能满足应用和会员的需要就行。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;其它&#34;&gt;其它&lt;/h4&gt;

&lt;p&gt;Cassandra是一个NoSQL数据库，是购买一家商业公司的服务，主要是用于各种Session的存储，并且支持跨区的同步复制。S3主要用于数据的备份。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;Netflix在每层上都考虑了失效，如何处理，但它每一层都没有做到尽善尽美，但不同层次的组合，却做到几乎完美的高可用性。当然Netflix构建高用性的系统还不只是我上面所列出的组件或工具。列出关键的部分是为了表达出&lt;code&gt;Design for Failure&lt;/code&gt;的理念是：故障不可避免，可以分层次的设计，通过多个技术方案组合应用，从而达到故障隔离，冗余恢复，实现整体的高可用性。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>再说说微服务</title>
      <link>http://lanlingzi.cn/post/technical/2017/0207_msa_think/</link>
      <pubDate>Tue, 07 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2017/0207_msa_think/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://lanlingzi.cn/images/msa/timg.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;why&#34;&gt;Why&lt;/h2&gt;

&lt;p&gt;我司从15年开始学习互联网的微服务构架，到今16年的全云化战略，微服务已作为架构体系的重要工作。但微服务看似美好，在IT界应用非常的成熟与成功，但这个本质没有革命性的技术架构，在我司却非常地难以落地。主要原因：传统的CT应用太过厚重，面临着软件交付模式完全不一样，历史包袱改造面临短期看不到收益的成本投入：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;IT界：软件是自运维，借助于微服务构架，DevOps工程化，以及相对扁平的组织结构。软件向微服务转变相对阻力比较小，按康威定律，组织决定架构，微服务构架与扁平化、轻小的、精英化的组织是完全匹配的。在微服务构架实施上可以快速迭代演进，同时形成回路反馈，架构更符合良性的发展。同时像BAT等公司，业务上爆发式的增涨，也会加速微服务构架软变与满足。&lt;/li&gt;
&lt;li&gt;我司：软件非自运维，做的是产品卖给运营商，DevOps当前无法直接打通。微服务构架对交付与运维来说，没有直接带来价值，反而会带来更多的问题。运营商是不可能像IT界每日构建灰度升级的。当然运营商自己也在改变，但这个改变是基础设施平台化，上层业务应用会拉入IT厂商，反而像我司这类传统的设备供应商会被旁落。说起来，这是另一个更大沉重的话题，不就再展开了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;what&#34;&gt;What&lt;/h2&gt;

&lt;p&gt;微服务架构转变当前遇到的各种问题，不是我们不实施微服务架构的理由。软件全云化，微服务这是趋势。再说说微服务对我们目前软件开发的核心价值吧：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;设计：微服务架构下，设计上可以重用已有微服务，反哺微服务仓库，达到软件功能更好的复用；同时由于微服务具有9大特性，使架构师能更好的守护软件架构。&lt;/li&gt;
&lt;li&gt;开发：相比原来组件化架构，每个开发人员负责的代码量减少，更能把事件做精；微服务架构下，一般会有像JDF或HSF的服务框架，使开发难度降低；业务功能的细分，基于服务化接口契约，使并行开发变成可能，工期缩短；细粒度快速验证，单个微服务的更容易稳定。&lt;/li&gt;
&lt;li&gt;部署：基于微服务的功能组合，可以按不同的特性交付，特性独立上线，而不原有的通过License开关控制；容量上可以按小颗粒度，自动化地伸缩，系统拥有更好的弹性。&lt;/li&gt;
&lt;li&gt;运行：可以小颗粒度，自动化地故障隔离，故障影响范围可控；按服务的滚动升级。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有上面的这些理由，难道我们还不选择微服务架构吗？架构上是OK的，但我司的矩阵性管理，有项目经理，有产品管理，有服务人员，有部门经理，有成本管理等，他们会看到，会认可吗？会有产品上收益来支撑吗？遗憾是目前没有，所以仅仅是研发体系上的隐性收益很难快速地推进。&lt;/p&gt;

&lt;h2 id=&#34;how&#34;&gt;How&lt;/h2&gt;

&lt;p&gt;在我司，那如何地渐进式地推进微服务架构，从四个维度架构视图展开：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;逻辑视图：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;存量代码按特性功能进行分析梳理，优先有商业价值的特性功能重构&lt;/li&gt;
&lt;li&gt;将老版本进程进行拆分与整合，对于相对稳定的原有组件尽量只服务化，而不微服务化&lt;/li&gt;
&lt;li&gt;新增特性直接按照微服务架构设计，并优先考虑重用已有拆分的微服务&lt;/li&gt;
&lt;li&gt;服务独立自治，多实例集群负荷均衡，可靠性服务内完成，服务内性能并发，服务使用者性能透明&lt;/li&gt;
&lt;li&gt;去中心化治理，无全局控制节点，避免全局故障&lt;/li&gt;
&lt;li&gt;服务划分原则：数据私有化，功能实例化，接口标准化，依赖最小化&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;部署视图：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;独立进程承载服务功能，在部署形态上做到可分可合&lt;/li&gt;
&lt;li&gt;服务尽量部署独立数据库，在设计上考虑Schema的隔离&lt;/li&gt;
&lt;li&gt;服务内的多进程统一服务控制节点管理&lt;/li&gt;
&lt;li&gt;服务可靠性，并发性统一由服务控制节点管理&lt;/li&gt;
&lt;li&gt;改造老进程新增服务接口，新老并存，调通后再去除老接口&lt;/li&gt;
&lt;li&gt;新服务新进程承载，调通后替换老进程&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;开发视图：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;按照服务构建开发视图&lt;/li&gt;
&lt;li&gt;按照服务构建测试工程&lt;/li&gt;
&lt;li&gt;按照服务适配个人构建&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;能力视图：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;配置能力完善，包括基础架构，研发工具，人员能力&lt;/li&gt;
&lt;li&gt;探索适合我司交付模式的微服务的开发模式&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总之，微服务架构落地不可能一蹴而蹴，更不可能一场运行就能解决的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Go性能优化小结</title>
      <link>http://lanlingzi.cn/post/technical/2017/0203_go_optimize/</link>
      <pubDate>Fri, 03 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2017/0203_go_optimize/</guid>
      <description>&lt;h2 id=&#34;内存优化&#34;&gt;内存优化&lt;/h2&gt;

&lt;h3 id=&#34;小对象合并成结构体一次分配-减少内存分配次数&#34;&gt;小对象合并成结构体一次分配，减少内存分配次数&lt;/h3&gt;

&lt;p&gt;做过C/C++的同学可能知道，小对象在堆上频繁地申请释放，会造成内存碎片（有的叫空洞），导致分配大的对象时无法申请到连续的内存空间，一般建议是采用内存池。Go runtime底层也采用内存池，但每个span大小为4k，同时维护一个cache。cache有一个0到n的list数组，list数组的每个单元挂载的是一个链表，链表的每个节点就是一块可用的内存，同一链表中的所有节点内存块都是大小相等的；但是不同链表的内存大小是不等的，也就是说list数组的一个单元存储的是一类固定大小的内存块，不同单元里存储的内存块大小是不等的。这就说明cache缓存的是不同类大小的内存对象，当然想申请的内存大小最接近于哪类缓存内存块时，就分配哪类内存块。当cache不够再向spanalloc中分配。&lt;/p&gt;

&lt;p&gt;建议：小对象合并成结构体一次分配，示意如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for k, v := range m {
    k, v := k, v // copy for capturing by the goroutine
    go func() {
        // using k &amp;amp; v
    }()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;替换为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for k, v := range m {
    x := struct {k , v string} {k, v} // copy for capturing by the goroutine
    go func() {
        // using x.k &amp;amp; x.v
    }()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;缓存区内容一次分配足够大小空间-并适当复用&#34;&gt;缓存区内容一次分配足够大小空间，并适当复用&lt;/h3&gt;

&lt;p&gt;在协议编解码时，需要频繁地操作[]byte，可以使用bytes.Buffer或其它byte缓存区对象。&lt;/p&gt;

&lt;p&gt;建议：bytes.Buffert等通过预先分配足够大的内存，避免当Grow时动态申请内存，这样可以减少内存分配次数。同时对于byte缓存区对象考虑适当地复用。&lt;/p&gt;

&lt;h3 id=&#34;slice和map采make创建时-预估大小指定容量&#34;&gt;slice和map采make创建时，预估大小指定容量&lt;/h3&gt;

&lt;p&gt;slice和map与数组不一样，不存在固定空间大小，可以根据增加元素来动态扩容。&lt;/p&gt;

&lt;p&gt;slice初始会指定一个数组，当对slice进行append等操作时，当容量不够时，会自动扩容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果新的大小是当前大小2倍以上，则容量增涨为新的大小；&lt;/li&gt;
&lt;li&gt;否而循环以下操作：如果当前容量小于1024，按2倍增加；否则每次按当前容量1/4增涨，直到增涨的容量超过或等新大小。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;map的扩容比较复杂，每次扩容会增加到上次容量的2倍。它的结构体中有一个buckets和oldbuckets，用于实现增量扩容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;正常情况下，直接使用buckets，oldbuckets为空；&lt;/li&gt;
&lt;li&gt;如果正在扩容，则oldbuckets不为空，buckets是oldbuckets的2倍，&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;建议：初始化时预估大小指定容量&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m := make(map[string]string, 100)
s := make([]string, 0, 100) // 注意：对于slice make时，第二个参数是初始大小，第三个参数才是容量
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;长调用栈避免申请较多的临时对象&#34;&gt;长调用栈避免申请较多的临时对象&lt;/h3&gt;

&lt;p&gt;goroutine的调用栈默认大小是4K（1.7修改为2K），它采用连续栈机制，当栈空间不够时，Go runtime会不动扩容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当栈空间不够时，按2倍增加，原有栈的变量崆直接copy到新的栈空间，变量指针指向新的空间地址；&lt;/li&gt;
&lt;li&gt;退栈会释放栈空间的占用，GC时发现栈空间占用不到1/4时，则栈空间减少一半。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;比如栈的最终大小2M，则极端情况下，就会有10次的扩栈操作，这会带来性能下降。&lt;/p&gt;

&lt;p&gt;建议：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;控制调用栈和函数的复杂度，不要在一个goroutine做完所有逻辑；&lt;/li&gt;
&lt;li&gt;如查的确需要长调用栈，而考虑goroutine池化，避免频繁创建goroutine带来栈空间的变化。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;避免频繁创建临时对象&#34;&gt;避免频繁创建临时对象&lt;/h3&gt;

&lt;p&gt;Go在GC时会引发stop the world，即整个情况暂停。虽1.7版本已大幅优化GC性能，1.8甚至量坏情况下GC为100us。但暂停时间还是取决于临时对象的个数，临时对象数量越多，暂停时间可能越长，并消耗CPU。&lt;/p&gt;

&lt;p&gt;建议：GC优化方式是尽可能地减少临时对象的个数：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;尽量使用局部变量&lt;/li&gt;
&lt;li&gt;所多个局部变量合并一个大的结构体或数组，减少扫描对象的次数，一次回尽可能多的内存。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;并发优化&#34;&gt;并发优化&lt;/h2&gt;

&lt;h3 id=&#34;高并发的任务处理使用goroutine池&#34;&gt;高并发的任务处理使用goroutine池&lt;/h3&gt;

&lt;p&gt;goroutine虽轻量，但对于高并发的轻量任务处理，频繁来创建goroutine来执行，执行效率并不会太高效：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;过多的goroutine创建，会影响go runtime对goroutine调度，以及GC消耗；&lt;/li&gt;
&lt;li&gt;高并时若出现调用异常阻塞积压，大量的goroutine短时间积压可能导致程序崩溃。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;避免高并发调用同步系统接口&#34;&gt;避免高并发调用同步系统接口&lt;/h3&gt;

&lt;p&gt;goroutine的实现，是通过同步来模拟异步操作。在如下操作操作不会阻塞go runtime的线程调度：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;网络IO&lt;/li&gt;
&lt;li&gt;锁&lt;/li&gt;
&lt;li&gt;channel&lt;/li&gt;
&lt;li&gt;time.sleep&lt;/li&gt;
&lt;li&gt;基于底层系统异步调用的Syscall&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面阻塞会创建新的调度线程：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;本地IO调用&lt;/li&gt;
&lt;li&gt;基于底层系统同步调用的Syscall&lt;/li&gt;
&lt;li&gt;CGo方式调用C语言动态库中的调用IO或其它阻塞&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;网络IO可以基于epoll的异步机制（或kqueue等异步机制），但对于一些系统函数并没有提供异步机制。例如常见的posix api中，对文件的操作就是同步操作。虽有开源的fileepoll来模拟异步文件操作。但Go的Syscall还是依赖底层的操作系统的API。系统API没有异步，Go也做不了异步化处理。&lt;/p&gt;

&lt;p&gt;建议：把涉及到同步调用的goroutine，隔离到可控的goroutine中，而不是直接高并的goroutine调用。&lt;/p&gt;

&lt;h3 id=&#34;高并发时避免共享对象互斥&#34;&gt;高并发时避免共享对象互斥&lt;/h3&gt;

&lt;p&gt;传统多线程编程时，当并发冲突在4~8线程时，性能可能会出现拐点。Go中的推荐是不要通过共享内存来通讯，Go创建goroutine非常容易，当大量goroutine共享同一互斥对象时，也会在某一数量的goroutine出在拐点。&lt;/p&gt;

&lt;p&gt;建议：goroutine尽量独立，无冲突地执行；若goroutine间存在冲突，则可以采分区来控制goroutine的并发个数，减少同一互斥对象冲突并发数。&lt;/p&gt;

&lt;h2 id=&#34;其它优化&#34;&gt;其它优化&lt;/h2&gt;

&lt;h3 id=&#34;避免使用cgo或者减少cgo调用次数&#34;&gt;避免使用CGO或者减少CGO调用次数&lt;/h3&gt;

&lt;p&gt;GO可以调用C库函数，但Go带有垃圾收集器且Go的栈动态增涨，但这些无法与C无缝地对接。Go的环境转入C代码执行前，必须为C创建一个新的调用栈，把栈变量赋值给C调用栈，调用结束现拷贝回来。而这个调用开销也非常大，需要维护Go与C的调用上下文，两者调用栈的映射。相比直接的GO调用栈，单纯的调用栈可能有2个甚至3个数量级以上。&lt;/p&gt;

&lt;p&gt;建议：尽量避免使用CGO，无法避免时，要减少跨CGO的调用次数。&lt;/p&gt;

&lt;h3 id=&#34;减少-byte与string之间转换-尽量采用-byte来字符串处理&#34;&gt;减少[]byte与string之间转换，尽量采用[]byte来字符串处理&lt;/h3&gt;

&lt;p&gt;GO里面的string类型是一个不可变类型，不像c++中std:string，可以直接char*取值转化，指向同一地址内容；而GO中[]byte与string底层两个不同的结构，他们之间的转换存在实实在在的值对象拷贝，所以尽量减少这种不必要的转化&lt;/p&gt;

&lt;p&gt;建议：存在字符串拼接等处理，尽量采用[]byte，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Prefix(b []byte) []byte {
    return append([]byte(&amp;quot;hello&amp;quot;, b...))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;字符串的拼接优先考虑bytes-buffer&#34;&gt;字符串的拼接优先考虑bytes.Buffer&lt;/h3&gt;

&lt;p&gt;由于string类型是一个不可变类型，但拼接会创建新的string。GO中字符串拼接常见有如下几种方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;string + 操作 ：导致多次对象的分配与值拷贝&lt;/li&gt;
&lt;li&gt;fmt.Sprintf ：会动态解析参数，效率好不哪去&lt;/li&gt;
&lt;li&gt;strings.Join ：内部是[]byte的append&lt;/li&gt;
&lt;li&gt;bytes.Buffer ：可以预先分配大小，减少对象分配与拷贝&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;建议：对于高性能要求，优先考虑bytes.Buffer，预先分配大小。非关键路径，视简洁使用。fmt.Sprintf可以简化不同类型转换与拼接。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;参考：&lt;br /&gt;
1. &lt;a href=&#34;http://skoo.me/go/2013/10/09/go-memory-manage-system-fixalloc&#34;&gt;Go语言内存分配器-FixAlloc&lt;/a&gt;&lt;br /&gt;
2. &lt;a href=&#34;https://blog.golang.org/strings&#34;&gt;https://blog.golang.org/strings&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Go依赖管理机制</title>
      <link>http://lanlingzi.cn/post/technical/2016/1120_go_deps_mgnt/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2016/1120_go_deps_mgnt/</guid>
      <description>&lt;p&gt;无论何种语言，依赖管理都是一个比较复杂的问题。而Go语言中的依赖管理机制目前还是让人比较失望的。在1.6版本之前，官方只有把依赖放在GOPATH中，并没有多版本管理机制；1.6版本（1.5版本是experimental feature）引入vendor机制，是包依赖管理对一次重要尝试。他在Go生态系统中依然是一个热门的争论话题，还没有想到完美的解决方案。&lt;/p&gt;

&lt;h2 id=&#34;看其它&#34;&gt;看其它&lt;/h2&gt;

&lt;p&gt;我们先来看看其它语言怎么解决，例举两种典型的管理方式：&lt;/p&gt;

&lt;h3 id=&#34;java&#34;&gt;Java&lt;/h3&gt;

&lt;p&gt;开发态，可以通过maven和gradle工具编辑依赖清单列表/脚本，指定依赖库的位置/版本等信息，这些可以帮助你在合适的时间将项目固化到一个可随时随地重复编译发布的状态。这些工具对我来说已经足够优雅有效。但maven中也有不同依赖库的内部依赖版本冲突等令人心烦的问题。尤其是在大型项目中的依赖传递问题，若团队成员对maven机制没有足够了解下，依赖scope的滥用，会让整个项目工程的依赖树变得特别的巨大而每次编译效率低下。运行态，目前Java也没有很好的依赖管理机制，虽有classloader可以做一定的隔离，但像OSGi那种严格的版本管理，会让使用者陷入多版本相互冲突的泥潭。&lt;/p&gt;

&lt;h3 id=&#34;node-js&#34;&gt;Node.js&lt;/h3&gt;

&lt;p&gt;npm是Node.js的首选模块依赖管理工具。npm通过一个当前目录的 package.json 文件来描述模块的依赖，在这个文件里你可以定义你的应用名称( name )、应用描述( description )、关键字( keywords )、版本号( version )等。npm会下载当前项目依赖模块到你项目中的一个叫做node_modules的文件夹内。与maven/gradle不同的是，maven最终会分析依赖树，把相同的软件默认扁平化取最高版本。而npm支持nested dependency tree。nested dependency tree是每个模块依赖自己目录下node_modules中的模块，这样能避免了依赖冲突, 但耗费了更多的空间和时间。由于Javascript是源码发布，所以开发态与运行态的依赖都是基于npm，优先从自己的node_modules搜索依赖的模块。
&lt;/p&gt;

&lt;h2 id=&#34;go-get&#34;&gt;go get&lt;/h2&gt;

&lt;p&gt;Go对包管理一定有自己的理解。对于包的获取，就是用go get命令从远程代码库(GitHub, Bitbucket, Google Code, Launchpad)拉取。并且它支持根据import package分析来递归拉取。这样做的好处是，直接跳过了包管理中央库的的约束，让代码的拉取直接基于版本控制库，大家的协作管理都是基于这个版本依赖库来互动。细体会下，发现这种设计的好处是去掉冗余，直接复用最基本的代码基础设施。Go这么干很大程度上减轻了开发者对包管理的复杂概念的理解负担，设计的很巧妙。&lt;/p&gt;

&lt;p&gt;当然，go get命令，仍然过于简单。对于现实过程中的开发者来说，仍然有其痛苦的地方：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;缺乏明确显示的版本。团队开发不同的项目容易导入不一样的版本，每次都是get最新的代码。尤其像我司对开源软件管理非常严格，开源申请几乎是无法实施。&lt;/li&gt;
&lt;li&gt;第三方包没有内容安全审计，获取最新的代码很容易引入代码新的Bug，后续运行时出了Bug需要解决，也无法版本跟踪管理。&lt;/li&gt;
&lt;li&gt;依赖的完整性无法校验，基于域名的package名称，域名变化或子路径变化，都会导致无法正常下载依赖。我们在使用过程，发现还是有不少间接依赖包的名称已失效了（不存在，或又fork成新的项目，旧的已不存维护更新）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而Go官方对于此类问题的建议是把外部依赖的代码复制到你的&lt;a href=&#34;https://golang.org/doc/faq#get_version&#34;&gt;源码库中管理&lt;/a&gt;。把第三方代码引入自己的代码库仍然是一种折中的办法，对于像我司的软件开发流程来说，是不现实的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;开源扫描会扫描出是相似的代码时，若License不是宽松的，则涉及到法律风险，若是宽松的，开源扫描认证确认工作也很繁琐。&lt;/li&gt;
&lt;li&gt;如何升级版本，代码复制过来之后，源始的项目的代码可以变化很大了，无明显的版本校验，借助工具或脚本来升级也会带来工作量很大。&lt;/li&gt;
&lt;li&gt;复制的那一份代码已经开始变成私有，第三方代码的Bug只能自己解决，难以贡献代码来修复Bug，或通过推动社区来解决。&lt;/li&gt;
&lt;li&gt;普通的程序问题可能不是很大问题，最多就是编译时的依赖。但如果你写的是一个给其他人使用的lib库，引入这个库就会带来麻烦了。你这个库被多人引用，如何管理你这个库的代码依赖呢？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;好在开源的力量就是大，Go官方没有想清楚的版本管理问题，社区就会有人来解决，我们已经可以找到许多不错的解决方案，不妨先参考下&lt;a href=&#34;https://github.com/golang/go/wiki/PackageManagementTools&#34;&gt;官方建议&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;vendor&#34;&gt;vendor&lt;/h2&gt;

&lt;p&gt;vendor是1.5引入为体验，1.6中正式发布的依赖管理特性。Go团队在推出vendor前已经在Golang-dev group上做了长时间的调研。最终Russ Cox在&lt;a href=&#34;https://github.com/kr&#34;&gt;Keith Rarick&lt;/a&gt;的proposal的基础上做了改良，形成了Go 1.5中的vendor:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不rewrite gopath&lt;/li&gt;
&lt;li&gt;go tool来解决&lt;/li&gt;
&lt;li&gt;go get兼容&lt;/li&gt;
&lt;li&gt;可reproduce building process&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;并给出了vendor机制的&amp;rdquo;4行&amp;rdquo;诠释：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If there is a source directory d/vendor, then, when compiling a source file within the subtree rooted at d, import &amp;ldquo;p&amp;rdquo; is interpreted as import &amp;ldquo;d/vendor/p&amp;rdquo; if that exists.&lt;/p&gt;

&lt;p&gt;When there are multiple possible resolutions,the most specific (longest) path wins.&lt;/p&gt;

&lt;p&gt;The short form must always be used: no import path can  contain “/vendor/” explicitly.&lt;/p&gt;

&lt;p&gt;Import comments are ignored in vendored packages.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;总结解释起来：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;vendor是一个特殊的目录，在应用的源码目录下，go doc工具会忽略它。&lt;/li&gt;
&lt;li&gt;vendor机制支持嵌套vendor，vendor中的第三方包中也可以包含vendor目录。&lt;/li&gt;
&lt;li&gt;若不同层次的vendor下存在相同的package，编译查找路径优先搜索当前pakcage下的vendor是否存在，若没有再向parent pacakge下的vendor搜索（x/y/z作为parentpath输入，搜索路径：x/y/z/vendor/path-&amp;gt;x/y/vendor/path-&amp;gt;x/vendor/path-&amp;gt;vendor/path)&lt;/li&gt;
&lt;li&gt;在使用时不用理会vendor这个路径的存在，该怎么import包就怎么import，不要出现import &amp;ldquo;d/vendor/p&amp;rdquo;的情况。vendor是由go tool隐式处理的。&lt;/li&gt;
&lt;li&gt;不会校验vendor中package的import path是否与canonical import路径是否一致了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;vendor机制看似像node.js的node_modules，支持嵌套vendor，若一个工程中在着两个版本的相的包，可以放在不同的层次的vendor下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;优点：可能解决不同的版本依赖冲突问题，不同的层次的vendor存放在不同的依赖包。&lt;/li&gt;
&lt;li&gt;缺点：由于go的package是以路径组织的，在编译时，不同层次的vendor中相同的包会编译两次，链接两份，程序文件变大，运行期是执行不同的代码逻辑。会导致一些问题，如果在package init中全局初始化，可能重复初化出问题，也可能初化为不同的变量（内存中不同），无法共享获取。像之前我们遇到gprc类似的问题就是不同层次的相同package重复init导致的，见&lt;a href=&#34;https://github.com/grpc/grpc-go/issues/566&#34;&gt;社区反馈&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以Russ Cox期望大家良好设计工程布局，作为lib的包&lt;strong&gt;不携带vendor更佳 ，一个project内的所有vendor都集中在顶层vendor里面。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;后续&#34;&gt;后续&lt;/h2&gt;

&lt;p&gt;Go的包依赖问题依旧困扰着开发人员，嵌套vendor可以一定程度解决多版本的依赖冲突问题，但也引入多份编译导致的问题。目前社区也在一直讨论如何更好的解决，将进入下一个改进周期。这次将在Peter Bourgon的主持下正式启动：&lt;a href=&#34;https://docs.google.com/document/d/18tNd8r5DV0
yluCR7tPvkMTsWD_lYcRO7NhpNSDymRr8/edit#heading=h.6fvzjp2juxex&#34;&gt;go packaging proposal process&lt;/a&gt;，当前1.8版本特性已冻结，不知这个改进是否会引入到1.9版本中。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;参考：&lt;br /&gt;
[1] &lt;a href=&#34;http://tonybai.com/2015/07/31/understand-go15-vendor/&#34;&gt;理解Go 1.5 vendor&lt;/a&gt;&lt;br /&gt;
[2] &lt;a href=&#34;http://www.infoq.com/cn/articles/golang-package-management&#34;&gt;Golang的包管理之道&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>团队管理</title>
      <link>http://lanlingzi.cn/post/thoughts/2016/1027_team_mgnt/</link>
      <pubDate>Thu, 27 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/thoughts/2016/1027_team_mgnt/</guid>
      <description>&lt;p&gt;最近由于Go语言项目，又带一个小团队。以前作为团队的Leader，总是遇到各种问题，尤其是如何管理好人很困惑。HW的组织相对是比较宽松的，内部号称是矩阵式，感觉一个团队的凝聚力个人还是来源于Leader的个人技术感召力。好吧，这个只是凭感觉的管理，这是远远不够的。&lt;/p&gt;

&lt;p&gt;作为一个技术团队的小Leader，整体来讲，它面临”业务“，”人“，”事“这三个方面的工作展开。这些是来源公司内牛人们的一些总结，我把他们纪录下来，是为了我更好地开展工作。
&lt;/p&gt;

&lt;h2 id=&#34;业务&#34;&gt;业务&lt;/h2&gt;

&lt;p&gt;虽是一个技术团队，所交付是面向客户交付的软件。两个方面是需要思考的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;价值贡献&lt;/li&gt;
&lt;li&gt;满意度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们常说”质量是我们最后尊严，业务价值是我们存在之本“，道理简洁朗朗上口，但也是最难做好的，做好又是一白遮百丑。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;面向业务：核心竞争力，价值识别与规划&lt;/li&gt;
&lt;li&gt;面向业务&amp;amp;解决方案：领域级，变革项目级规划、运作&lt;/li&gt;
&lt;li&gt;满意度管理：面向业务（客户，用户）；面向解决方案；面向部门；面向合作伙伴&lt;/li&gt;
&lt;li&gt;Top产品，问题的攻关&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;人&#34;&gt;人&lt;/h2&gt;

&lt;p&gt;人的运用，对于Leader来说，是一项非常具有挑战的事，这需要Leader有很高的EQ与IQ。总结起来选用育留四个字：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;选&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;亲自招聘，选择合适的人&lt;/li&gt;
&lt;li&gt;已有员工中骨干识别&lt;/li&gt;
&lt;li&gt;非关键外包合作&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;角色与岗位排兵布阵&lt;/li&gt;
&lt;li&gt;合作外包&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;育&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;能力引入：公司内部交流：经验总结交流分享；部门内外专家交流；业界交流：参加相关技术峰会；高级顾问培训交流&lt;/li&gt;
&lt;li&gt;能力培养：提升人员技能；组织能力建设&lt;/li&gt;
&lt;li&gt;全程关注：事前辅导，事中监控，事后总结&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;留&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;绩效辅导&lt;/li&gt;
&lt;li&gt;即时激励&lt;/li&gt;
&lt;li&gt;组织氛围：员工座谈，组织集体活动，员工关怀（问题员工识别管理，异常事件处理）&lt;/li&gt;
&lt;li&gt;岗位流动&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;事&#34;&gt;事&lt;/h2&gt;

&lt;p&gt;以前作为一个团队的小Leader，感觉一天都在忙，但不知在忙些什么。管事恨不得像孙猴子能分身出来，但健身乏术，如何正确合理地授权也是考验Lader的水平。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TopN问题与任务跟踪管理&lt;/li&gt;
&lt;li&gt;KPI管理：现状问题分析；改进计划（包括措施）；改进监控；达成评估&lt;/li&gt;
&lt;li&gt;风险管理&lt;/li&gt;
&lt;li&gt;技术持续改进：新技术引入；优秀实践；&lt;/li&gt;
&lt;li&gt;质量持续改进：质量文化；质量监控，问题日清日结；质量回溯；质量改进&lt;/li&gt;
&lt;li&gt;流程运作持续改进&lt;/li&gt;
&lt;li&gt;知识管理&lt;/li&gt;
&lt;li&gt;跨部门协同&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>软件开发知行合一</title>
      <link>http://lanlingzi.cn/post/thoughts/2016/0131_unity_knowledge_action/</link>
      <pubDate>Sun, 31 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/thoughts/2016/0131_unity_knowledge_action/</guid>
      <description>&lt;p&gt;最近在走读团队的代码，有时实在是看不下去。不是因为他们的代码编写有很多Bugs，而是没有设计实现太复杂了。当面对众多的需求需要快速实现，没有几个人会去思考代码怎么写结构才更合理，而是在不断去搬砖垒需求。当我去咨询他们为什么要这样实现时，每个人能只能说出一，不知其二。即使自己写的代码，也不知道当初为什么这么实现。&lt;/p&gt;

&lt;p&gt;同时，我们团队中不乏有各种兴趣小组。例如学习新的技术框架，交流设计模型，讨论重构技巧、性能优化经验。而实际在操作层面上，代码却正如前面所讲，有时真的不堪入目。由于这近在看王阳明传，突然想到我们没有&lt;code&gt;知行合一&lt;/code&gt;啊。

&lt;strong&gt;知&lt;/strong&gt; ：一方面是我们对技能掌握，如程序语言知识，设计模式，框架类库等；另一面是我们对需求理解，如场景梳理，用例分析，关键指标等。
&lt;strong&gt;行&lt;/strong&gt; ：能根据掌握的知识技能，以及对需求的认识应用于项目中，能过代码转化为实际客户所需的产品。&lt;/p&gt;

&lt;p&gt;结合按王阳明的学说，做为一名合理的软件工程师，则需要格物致知，知行合一，良知和致良知。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;格物致知&lt;/strong&gt; ：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;格需求。对需求不断地格，才能知道客户真正需要什么。因为客户的提出需求时，往往是感性的，非技术化的描述，也可能是模糊不清晰的。那就需要我们不断去交流与探讨，才能明白客户的痛点，进而知行合一，指导你编码，做出满足客户真正需要的东西。&lt;/li&gt;
&lt;li&gt;格技术。软件开发会涉及到很多的知识，尤其是大型的项目。我们面对操作系统，各种框架程序，以及各种软件工程方法。我们需要不断地格，去深入探本究源，明白什么场景下，使用什么技术是最优的。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;知行合一&lt;/strong&gt; ：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;知而为行。知行合一很好理解了，简单的就是“知”和“行”统一。理论与实践想结合，一切的实践行动又必须有理论支撑。所想即所写，所写即所需。你能编写出来的代码才是真正知道的需求，你真正知道的需求你就一定能编写出来代码。&lt;/li&gt;
&lt;li&gt;行而促知。我们不断地学习与交流，本身没有什么问题。其实如果没有实践的切身体验，是难以有较深的认知的。往往是学完也说不出一个所以然。知行合一，学习必须时刻结合实践行动，这样才能真正的掌握并不断的进步。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;良知和致良知&lt;/strong&gt; ：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;良知。良知是人内心深处的心声。软件开发的良知是程序员做事的标准。显然，不断地只按需求去垒代码不是标准，能跑起来的代码也不是标准。软件开发的标准可能很多，不同的人有不同的看法。但一个团队一定要代码编写标准化，开发流程标准化。没有规矩成不了方园，标准化才能提高我们的效率。&lt;/li&gt;
&lt;li&gt;致良知。找到标准（良知），然后去做到知行合一（致良知）。如果程序的良知是优秀的代码，那致良知就是我们不断地为实现优秀的代码去努力。优秀的代码涵盖代码的可读性，可理解性，同时还需要兼顾代码的可扩展性，可维护性。不要对自己编写的代码放任不理，识别代码的坏味道，编程的过程实际是一个不断重构改进的过程。古人说“三日省吾身”，编程也需要不断地反思。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>重构已死</title>
      <link>http://lanlingzi.cn/post/technical/2016/0123_refactor_death/</link>
      <pubDate>Sat, 23 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2016/0123_refactor_death/</guid>
      <description>&lt;p&gt;上周在食堂吃饭，遇到同事聊起最近的系统重构，她说这一批的新员工不如13年的一批，就一个看似简单的问题也是折腾很久，重构的周期越拉越长。我作为这次的重构的特性SE，可以说也是硬着头皮上。我是越来越反感重构，尤其是涉及到多个模块的重构。在新年的聚餐上，我说我给你挖了坑，你来填坑，让我感到非常惭愧的，即又不得做这些事。&lt;/p&gt;

&lt;p&gt;在现阶段项目交付变得越来越难，一方面我们面对众多的需求，做还是不做并不是你能轻易决定的；而另一方面我们又想从架构上解决可以快速满足需求。但本质的是这几个月内，人的技能与意识没有根本性的变化。在大家没有主人翁的精神下，说来说去也是为了需求在垒代码。即使你想从代码结构上重新设计，让系统更松的耦合性，更好的扩展性。受于项目进度冲击，以及代码实现者的被动，最终也会变得让你不想回头多看一眼。
&lt;/p&gt;

&lt;p&gt;编程如果仅仅越考虑短期实现项目需求目的肯定是不好的，但想通过强制的管理手段，或重构手段来想延长它的生命周期也并一定能行得通。当同一份代码是多人开发与维护，并在领导眼中的谁有时间谁就上的话。本意可能是想通过多人的备份，或共同完成以期缩短工期。其实这种做法无疑更是加重了代码朝腐化之路上走的趋势。&lt;/p&gt;

&lt;p&gt;重构有很多的手法或方法理论，其核心都会有提到&lt;code&gt;不改变软件的外部行为&lt;/code&gt;，是对&lt;code&gt;软件内部结构&lt;/code&gt;进行修改与调整。这实际上是非常难以做到的，我们是如何去评估不改变软件的外部行为，充分的测试能保证吗？显然就我们目前的测试能力来看，这简单是非常美好的梦想。尤其是具有一些年头的代码，或者又是人员变化较频繁的代码，看上去并不清爽的代码，至少还能正常的工作，一旦重构不知会丢失多少其中通过各种手段修改出来的小功能点。&lt;/p&gt;

&lt;p&gt;今天的软件交付，可能说由于整体的需求是具有多变性，给软件开发带来不确认性。不确定就会产生怀疑和恐惧，我们经常会说，软件架构是要架构未来，不是解决当下问题。当不确定性还不算太多的时候，我们还在架构层面上来推演，整个软件系统的大致方向可以被预测，然后在此基础上不断地演化。而当不确定性实在太多的时候，对软件的要求就变成了&lt;code&gt;可丢弃&lt;/code&gt;。换句话说，你开发的所有软件，从一开始，你就应该做好很快被丢弃的准备。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;采用开源：尤其是Github让开源的推广与使用变得越来越简单，开源软件在商用软件领域成为了越来越主流。即使你开发的是非常重要的商用软件也不需要自己从头开始，自己实现并一定比开源实现的好。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;平台框架：平台软件的目的是让通用的能力重用与沉淀。业务领域更倾向于采用面向领域的DSL描述简化开发，代码量要求是越来越少。目前各种基础框架越来越成熟，基于基础构架上构建，可以在最短时间内以最少代码量做出一个符合要求的软件。并且业务层不需要过多的设计，因为大部分设计已经蕴含在框架内。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;职责单一：可以把系统拆多功能单一的服务，符合单一职责原则，做且仅做一件事。这样代码量就不会太多，也不需要频繁地添加新的功能，变化少就不不会导致不稳定，所以这样代码烂也烂不到哪里去。另一方面功能单一，在其上的工作团队成员也会很少，四五个人能搞定的代码，它的也不会因为多人的经手变得不可维护。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在面对需要快速迭代交付的项目下，软件开发变得越来越轻量化下。尤其是在微服务架构下，软件开发其实可以不需要重构，该烂的就让它烂掉。对于单个微服务或单个小的模块内的代码重构意义也变得越来越小。如果这个微服务真的到了无法满足需求情况下，那没有必要对它进行重构，重写一个就行了。所以在这样的情况下&lt;code&gt;“重构已死”&lt;/code&gt;，其实又是系统中另外一种&lt;code&gt;“重生”&lt;/code&gt;，就像人的身体一样，做换只手的手术可能影响非常地大，如果只是细胞不断地死去，新的又产生替换，你是感觉不到有什么影响。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>参加ArchSummit北京站感受</title>
      <link>http://lanlingzi.cn/post/technical/2015/1227_bj_archsummit/</link>
      <pubDate>Sun, 27 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2015/1227_bj_archsummit/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://q.infoqstatic.com/ASSZ2015/LOGO/AS-LOGO358x146.png&#34; alt=&#34;ArchSummit&#34; /&gt;&lt;/p&gt;

&lt;p&gt;参加ArchSummit北京站已有一周时间，一直没有时间来梳理一下。整体来说，这次的北京之行，不是很满意，可能是这类会议听多的原因，感觉ArchSummit的质量是越来越差了，没有什么新鲜感，觉得不值那6K的价格。&lt;/p&gt;

&lt;h2 id=&#34;组织不足&#34;&gt;组织不足&lt;/h2&gt;

&lt;p&gt;12月份的北京已是非常的干冷，可能由于我在南方呆久了，一到北京是极其地不适应，在北京三天多的时间，嘴唇开裂，到现在还没有完全好干净。离开北京的那一天，正好又感受了一下北京正宗的霾，帝都的人们活得真不容易啊。
&lt;/p&gt;

&lt;p&gt;为什么说ArchSummit组织不足呢？InfoQ也算是组织过多次大型会议的公司，但这一次比我之前参加InfoQ组织的任何会议都差，更无法与阿里组织的云栖会议相比。一个是以组织会议赚钱，一个是以个会议来打造生态。这次的ArchSummit是在北京国际个会议中心举行，每个分会场我都差不多的参加过，明显感觉组织不足:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个分会场演讲时，大门紧闭，空间质量非常的差，又没有充足的通风设备，感觉非常的窒息。&lt;/li&gt;
&lt;li&gt;工作人员能力不行，第一天下午，有几个分会议室由于投影没有准备好，拖时半个多小时，也不见中途主持人来了说一声，最后连声道歉都没有。&lt;/li&gt;
&lt;li&gt;几个分会场的投影效果差，灰蒙蒙的看不清楚。&lt;/li&gt;
&lt;li&gt;连个矿泉水瓶上都是广告，并且不是每个位置都摆放好水，而是需要自己去指定位置去拿。有的分会场甚于连矿泉水都没有见到，准备的份数太少，6K的价格连个水都喝不到。&lt;/li&gt;
&lt;li&gt;就餐地方太小（又是自助餐），效率低下，大量的人员挤在走廊上，我是差不多等了30多分钟才能进餐厅吃饭。大量的人员挤在一起存在安全风险。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;两天的ArchSummit大会日程比较紧凑，再加上大多数时候有六个专题在并行，因此每个人能够真正去听的课程不会太多。我们也是只能选择地去听，但是每个演讲介绍不足，有些演讲名字高大上，听了之后，感觉有点上当，部分讲师存在水分，这里就不直说了。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;不过，参加ArchSummit大会，还是听到一些业内公司的技术分享，尤其是互联网企业，在应用新技术方面还是比较超前的。相对我们电信行业来说，我们遇到的问题有些是相似的，甚至部分问题的解决办法也与我们曾经想过的一些方案类似，只是他们早已经落地并且做到极致了。有很多东西对我们值得参考，可以说从开源使用、技术形态，运作方式，远远走在我们的前面了。&lt;/p&gt;

&lt;h2 id=&#34;paas平台&#34;&gt;PaaS平台&lt;/h2&gt;

&lt;p&gt;目前稍具规模的互联网公司，都会自建数据中心。而互联网的业务又有如下特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;业务需要快速上线，唯快不破&lt;/li&gt;
&lt;li&gt;业务形态众多，迭代周期快&lt;/li&gt;
&lt;li&gt;数据处理量大，海量请求和高并发的挑战&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;支撑业务的发布，上线，运维，都需要对业务应用的全生命周期管理，各个公司都有一套平台，他们或多或少都能称得上内部的PaaS平台。而PaaS平台核心：&lt;/p&gt;

&lt;h3 id=&#34;分布式框架&#34;&gt;分布式框架&lt;/h3&gt;

&lt;p&gt;首先是《蚂蚁金服金融级PaaS平台构建之道》分享，阿里在国内技术一直算是走到前列。这次带来的演讲，蚂蚁金服的分布式服务注册中心（DSR），与阿里其它系的Dubbo，HSF都差不多。他们的目标都要解决应用服务化后，服务注册发现问题，可以说是未来PaaS平台中，服务注册发现将成来PaaS的核心中的核心。&lt;/p&gt;

&lt;p&gt;后一场听了《主流容器SDN技术与微服务架构实践》，来自七牛的分享。虽然演讲的内容是容器的SDN技术（算不上大范围的SDN），也同时点到微服务架构。虽然他们所讲的容器方案都说是自研的，但整体上感觉与K8S的设计是相似，甚至像Pod之类的概念来也是借鉴来的。在容器环境下的同时也要解决分布式的服务发现问题，他们采用是DNS机制。服务路由上支持L4与L7的负载均衡，对业务无侵入。基于安全组的服务Discovery，虽然没听太明白，感觉跟K8S的Proxy机制是差不多的。&lt;/p&gt;

&lt;h3 id=&#34;中间件服务&#34;&gt;中间件服务&lt;/h3&gt;

&lt;p&gt;在《蚂蚁金服金融级PaaS平台构建之道》中初步介绍了分布式消息(DMS)、分布式数据源（DDS），分布式事务（DTS）的一些使用场景与技术特点。在云环境下，中间件服务必不可少，让业务应用只关注自己的业务逻辑。中间件服务要面对的是一个复杂、不断变化的计算环境。抽象出业务的公共能力服务化。使用中间件服务，可以简化业务应用在一些通用技术的成本，如数据一致性，安全控制，高性能，可靠性等。而中间件技术正在呈现出业务化、服务化、一体化的趋势发展。高可用性，自管理性，业务适应性是当前中间件服务面临的挑战。&lt;/p&gt;

&lt;h3 id=&#34;弹性扩展&#34;&gt;弹性扩展&lt;/h3&gt;

&lt;p&gt;在云计算中，引入虚拟化技术，采用弹性伸缩是老生常谈了，一键式按需弹性，基于性能采集的自动弹性。听了《微众银行基于自主可控技术的分布式架构实践》，给我对弹性带了新的思考。互联网+的应用是：海量用户，海量交易，海量数据。这要求对系统在架构设计上充分考虑容量的扩展性，性能的扩展性。&lt;/p&gt;

&lt;p&gt;微众的架构特点是分布式松耦合架构+一主两从节点强制同步的架构。在分布式松耦合架构是按客户群来水平分割，一个节点上涵盖多个客户业务。分布式多节点是分散风险，如果有节点受损，也是部分客户有影响。而每个节点上又采用一主两从节点强制同步，来提高整个系统的冗余。整个系统以客户为单元可控分布，将客户量、交易频繁度与系统负载之间的关系解耦。随着客户量增加或客户交易频繁度的增加,系统负载也会随着增加：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;横向扩展(Scale Out)解决用户量增加&lt;/li&gt;
&lt;li&gt;纵向扩展(Scale Up)解决交易频繁度增加&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;并且严格要求，横向扩展只能解决用户量问题，不能通过纵向扩展来解决用户量问题，反之亦然。&lt;/p&gt;

&lt;h3 id=&#34;容灾备份&#34;&gt;容灾备份&lt;/h3&gt;

&lt;p&gt;云计算环境下，容灾备份也是需要重点考虑的，容灾设计强调的是系统对外界环境影响具备快速响应能力，尤其是当发生灾难性事件并对IDC节点产生影响时，能够具备节点级别的快速恢复能力，保障系统的持续可用。像微众介绍IDC2.0中提到的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据库三中心集群化部署&lt;/li&gt;
&lt;li&gt;三数据副本强同步&lt;/li&gt;
&lt;li&gt;应用多中心多活部署&lt;/li&gt;
&lt;li&gt;应用多中心多实例多活部署&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;蚂蚁金服金服提到的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;两地三中心&lt;/li&gt;
&lt;li&gt;异地多活&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;支付宝有一个专题《支付宝的高可用与容灾架构演进》，我觉得有意思的是其中的单元化与容灾。单元化应该是微服务化中一种具体运用吧。什么是支付宝的单元化：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;核心业务,核心剥离：数据按照UserID拆分,多机房部署,调用封闭,部分数据,不共享&lt;/li&gt;
&lt;li&gt;非核心业务,长尾独立：不能按照UID拆分，核心不依赖长尾&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;单元化的实现思路：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;水平拆：交易、支付、账务等,每个单元只有部分数据&lt;/li&gt;
&lt;li&gt;上层单元化改造：从DB层往上延伸水平拆分概念,包括应用层到入口层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在容灾同步上，是基于单元化的多中心同步，这已打破我们对原有容灾备份的认识，基于单元化的容灾同步，可以细粒度的控制，解决数据一致性和时效性问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;基于DB同步的数据复制：延时非敏感业务的异地复制方案;部分业务数据,可忍受3s时效性延迟(比如大部分的配置 数据)&lt;/li&gt;
&lt;li&gt;基于消息系统的数据复制：对于延时非常敏感的业务,更低延时的实现方案;上层基于应用进行复制,减少延时。底层 DB主备同步同时进行&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;高效运维&#34;&gt;高效运维&lt;/h3&gt;

&lt;p&gt;开发团队快节奏的版本迭代，以及服务的快速上线的要求，驱动着PaaS平台要提供出更为高效的运维服务。高效运维的思路是建立以 &lt;strong&gt;应用服务&lt;/strong&gt; 为核心的管理标准体系。把运维能力服务化(API)，使运维的能力无处不在。高效运维，综合几个公司的介绍主要需要如下几个系统设计：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;发布系统：负责应用服务的上线，应用服务的资源管理，扩容，权限管理，支持Beta发布，灰度升级。&lt;/li&gt;
&lt;li&gt;监控系统：通用+自定义监控配置,运维+开发可以时刻关注自己的服务状态和质量。&lt;/li&gt;
&lt;li&gt;全链路系统：复杂的分布式系统，一次点击，几十次的RPC调，需要全链路跟踪，出了问题,如何快 速定位到故障点。&lt;/li&gt;
&lt;li&gt;限流与降级：限流,Web层,防止被流量打垮；降级,App层(服务化),保障核心应用&lt;/li&gt;
&lt;li&gt;容量评估：基于全链路的压测手段、数据分布的模拟方法、关键场景调用量预估&lt;/li&gt;
&lt;li&gt;蓝绿发布：即多站点的灰度。具体操作流程：切流（将待发布机房流量切走）-&amp;gt; 机房发布（待发布机房全应用并行发布）-&amp;gt; 引流验证 （逐步按规则引流至100%）-&amp;gt;
  流量交换（将全部流程切换到已发布机房）-&amp;gt; 机房发布（另一个机房全应用并行发布）-&amp;gt; 分流还流（分流规则还原，两机房各50%）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;服务化&#34;&gt;服务化&lt;/h2&gt;

&lt;p&gt;今年IT界是对服务化异常的火爆，系统的稳定和流畅依赖好的应用架构，服务化治理如何规划和落地，是众多厂商系统的痛点。&lt;/p&gt;

&lt;p&gt;首先是来自1号店订单系统对SOA化的分享，SOA是一种架构模式,是设计原则,不是技术规范。狭义的SOA：Service化， 标准化、模块化、组件化。广义的SOA：模式、原则、思想。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Service化：1）分层结构，基础Service不含业务逻辑,只封装基本的数据操作。业务(聚合)Service封装业务逻辑甚至是全部的业务逻辑。2）Service层次调用，上层可以调用下层、下层不可调用上层、同层间可互相调用，调用链长度不超过3级、不循环调用。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;服务粒度划分：1）迷你裙定律。2）细粒度的服务(fine-grained)提供相对较小的功 能单元,或交换少量的数据。细粒度的服务使服务更容易被组装。3）粗粒度的服务(coarse-grained)则是在一个抽象 的接口中封装了独立的业务/技术能力,减少服务请求交互的次数。粗粒度的服务适合更广泛的需求。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;再次是来自Twitter的服务化思路分享：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;单体：牵一发而动全身&lt;/li&gt;
&lt;li&gt;分拆：把单体分成多个模块&lt;/li&gt;
&lt;li&gt;服务化：把模块按功能服务化&lt;/li&gt;
&lt;li&gt;平台化：模块功能中部分服务化为通用服务，通用服务提供一般化服务，平台化&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;

&lt;p&gt;在不断寻求性能更好、速度更快、成本更低的云计算核心技术中，容器技术是目前最吸引人注意的技术之一。尽管除去效率、速度和成本等方面的优势以外，容器技术还存在一些安全上需要斟酌的问题，但是其实际表现仍然得到了肯定。还是借用其中的分享内容来说明一下Docker。&lt;/p&gt;

&lt;p&gt;在遇到Docker之前：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;混乱的环境：Java, Golang, Ruby&lt;/li&gt;
&lt;li&gt;混乱的配置：Upstart, authorized_keys, dependency, 各种脚本&lt;/li&gt;
&lt;li&gt;混乱的监控：ErrorReporter, Message&lt;/li&gt;
&lt;li&gt;混乱的资源：计算资源与预估不匹配&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;导致的结果是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;环境不匹配导致,测试跟生产不一致&lt;/li&gt;
&lt;li&gt;配置混乱导致事故频发&lt;/li&gt;
&lt;li&gt;监控不统一导致运维难上加难&lt;/li&gt;
&lt;li&gt;资源效率低导致成本很高却达不到相应目标&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而Docker具有如下特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;构建快：应用+运行环境 = 镜像&lt;/li&gt;
&lt;li&gt;启动快：容器相比于虚机,更轻量级&lt;/li&gt;
&lt;li&gt;迁移快：应用以容器的方式标准化交付,标 准化运行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;去年Docker主要是在吵作概念，而今年很多的互联网厂商已在使用Docker，本次Docker中都分享各自针对Docker的一些定制化修改及踩过的各种坑，所遇到的困难和走过的弯路。&lt;/p&gt;

&lt;p&gt;当然这些坑不是阻当我们不使用Docker的理由，Dockerk只是一个系统架构优化的承载体。来自Coding.net的分享最后总结的比较好，Docker会对软件，流程带入变革与影响，是否采用Docker，系统都需要关注如下三个方面，只是Docker让你不得不关注他们：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;软件架构的升级：微服务、无状态、数据执行分离&lt;/li&gt;
&lt;li&gt;研发体系、环境管理理念的升级：容器化、代码化、自动化&lt;/li&gt;
&lt;li&gt;资源管理理念的升级：Pet vs Cattle，多留点富余量，迁移能力比压榨能力更重要&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>我为什么喜欢GoLang</title>
      <link>http://lanlingzi.cn/post/technical/2015/1113_why_love_go/</link>
      <pubDate>Fri, 13 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2015/1113_why_love_go/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://img3.imgtn.bdimg.com/it/u=3850601748,68654193&amp;amp;fm=21&amp;amp;gp=0.jpg&#34; alt=&#34;gopher&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从8月份到现在，一直在公司尝试用Go写点东西。虽然我们几乎是清一色的Java开发，但我还是愿意在同事之间推广Go，有时间还是学学Go吧。&lt;/p&gt;

&lt;h2 id=&#34;认识go&#34;&gt;认识Go&lt;/h2&gt;

&lt;p&gt;我大概是一个不太执着的语言控，什么语言喜欢玩玩，在大约在12年时，就开始自学Go，但仅仅是看看语法，写写Helloword之类的小程序而已。在13年底，我被抽去分析Cloud Foundry的架构与实现机制。当时的CF是V2版本，其中的GoRouter，HM9000已采用Go重写，另外消息总线NATS也有Go语言版本。而我又重点分析了NATS，HM，以及部分GoRouter的Go源码。发现居然Go能写出如此简练的代码。性能验证时，又发现Go版本的NATS比Ruby版本的强得不是一点点，我们在单板上测试出有50万+的QPS。14年做融合架构，又把我们原有的消息中间件RabbitMQ换成了NATS。当时的出发点主是能与CF通过NATS融合拉通，另外是看重它的高性能。而RabbitMQ是erlang写的，部门熟悉erlang人几乎没有，维护成本高。当然到现在来看，NATS太简单了，并不是个消息队列，很多的特性都没有。
&lt;/p&gt;

&lt;p&gt;14年的Docker以席卷全球之势火了一把。在15年，我又投入到平台集成Docker的分析，于是又开始了Go语言之旅，重点研究了Docker Distribution的代码，以及由其它部门开发的Index等相关部件的代码（都是基于Go）。自己也是顺便练练手，如把系统中Java的通用加解密库（是基于AES与HamcSHA256之上的封装库），转换Go实现。经测试发现原来在Java对于HamcSHA256迭代6W+次数时需要差不多一分钟，而Go只需要几秒。由于系统需要对接Docker的API，涉及到Http Hijack，于是又得去分析Docker源码中这一块是怎么实现的，把它的实现转换成Java（虽有开源的Java Client API，但不能满足我们的要求）。所以差不多就是干些Java转Go，Go转Java的体力活。整个版本开发中也协助定位一些Docker相关的问题，需要走读Docker代码。整体来说，我写的Go代码不是太多。&lt;/p&gt;

&lt;h2 id=&#34;曾经的痛苦&#34;&gt;曾经的痛苦&lt;/h2&gt;

&lt;h3 id=&#34;c&#34;&gt;C++&lt;/h3&gt;

&lt;p&gt;十多年的编码经验,一半是做C/C++开发，一半是Java。目前还记忆犹新的是，在08年写的一个消息缓存中间件，大量使用了共享内存、内存分片技术、大文件操作，以及缓存淘汰算法（主要与业务特性相关）。原本只是一个消息缓存+持久化，但后来做着做着已不再是一个纯粹的缓存，参杂着业务复杂的逻辑，最终也导致代码质量不可控。一出问题就是踩地址（用于大消息缓存，原本设计是小消息），CoreDump文件分析困难。现在来看，其实如果只是做纯粹的缓存与持久化，Redis也能满足当时的需求，可惜那时开源没有现在这么火，更没有听说有Redis，连Memchached都没有听过。后来在09年与10年，又负责过另一个产品的版本稳定与性能提升。在那段日子里，我与另一个兄弟不知解决多少个CoreDump问题，现在还记得一个踩栈地址的问题整整花了我一周时间，通过猜测CoreDump中的地址信息加上反复走读代码才找到问题的原因。为了压榨单板的性能，在做优化时真是极其语言的偏门用法，尤其是在老的代码上为了发挥并发多线程的能力，代码写得真是惨不忍睹（那时也接触过erlang，发现erlang进程模型是多美好）。目前我司还有很多产品为了提高性能与降低时延，甚至是在内核做了一些修改，如零拷贝技术。这些性能上极致的代码也只能是少数人能看得懂。10年还做一件非常痛苦的工作，就是把跑到Linux上代码移植到Window，主要用于做开发验证仿真工具。即使采用MGWin，也是苦不堪言，其中的困难是谁做谁知道。&lt;/p&gt;

&lt;h3 id=&#34;java&#34;&gt;Java&lt;/h3&gt;

&lt;p&gt;10年底开始做云计算，又开始做Java开发（之前也开发过Java，主要是JNI）。使用C开发时，没有什么开源框架可选，但Java的框架是一大堆，J2EE，OSGI，Spring&amp;hellip;无论是哪种，框架都是又臭又硬，太厚重了。大量使用第三方的开源Jar管理也是非常困难。即使我们采用Maven来做工程管理，也是相当的复杂，尤其是对一个大型系统，全编译构建时间都可以与原有C/C++有得一拼（我之前经历过的C/C++写的系统，全编译要花差不多一天时间，拿现的DevOps理念是不可想象的），也尝试使用过Maven的并行编译，但由于部分的Mavne插件不支持也放弃了，只能换成多台机器分布式编译。Java运行环境到14年我们才换成JDK8，之前一直采用JDK6，写多了就觉得Java的语法是硬伤，太不灵活，尤其是一堆的Getter与Setter（采用lombok简化），什么都得先定个interface，总之代码看起不是清爽简洁。Java的打包发布更是一个噩梦，虽有Maven管理，但对于一个大型系统，差不多一百号人的开发团队，系统整体打包是差不多2G的压缩包。我们是花了不少时间去清理不同版本的第三方Jar包（公司要求同一产品依赖的版本要归一），每次做版本升级，换一个Jar的版本会牵出一堆的Jar依赖要升级，也是苦不堪言，其中的痛苦是谁做谁知道。经过不断地努力，目前整个团队使用第三方Jar登记还有100+，整体打包差不多1G的压缩包，对于严格的电信行业说，任何第三方Jar包要做内部开源扫描认证，这是一项浩大的工程。在06年做Java时，为了性能比拼，JVM的性能参数调优也是一个非常要有技术的活，吞吐量与时延两者不能兼顾。&lt;/p&gt;

&lt;h2 id=&#34;再来说go&#34;&gt;再来说Go&lt;/h2&gt;

&lt;h3 id=&#34;缘由&#34;&gt;缘由&lt;/h3&gt;

&lt;p&gt;我为什么喜欢Go，最重要的原因是我目前从事云计算领域的研发。总结之前说了这么多的痛苦，对于C/C++:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;开发效率低，定位问题复杂，对开发者技术要求高&lt;/li&gt;
&lt;li&gt;C/C++偏底层，对系统依赖度高，系统迁移困难&lt;/li&gt;
&lt;li&gt;开源框架少，系统API只向后兼容，维护成本高&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;那Java呢：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;框架臃肿庞杂，反而简单问题复杂化&lt;/li&gt;
&lt;li&gt;规范繁多，实现框架也多，选择太多，产品容易被框架绑定&lt;/li&gt;
&lt;li&gt;语法啰嗦，全OOP化不灵活&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;技术特征&#34;&gt;技术特征&lt;/h3&gt;

&lt;p&gt;当然，无论是C/C++还是Java，如果项目决策需要，我还是会继续使用他们。他们的成功有他们成功的原因，纯粹的语言比较都有各自的优缺点。我在这也不是为了说喜欢Go而去有意贬低他们，只是列一下个人觉得遇到痛苦。为什么我喜欢Go，主要原因还是它在云计算相关产品的发力，像Google的K8S，Docker，CoreOS，CloudFoundry等等都大规模地使用Go。在学习与使用Go的过程中，被他的设计理念所折服，它是一个面向工程而简化的语言。从语言学上来说，他可能不是最好的语言，但对于大多数的系统，一般都需要兼顾开发效率，运行性能，维护成本。而Go似乎在这几个方面能做到很好平衡。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;开发效率

&lt;ul&gt;
&lt;li&gt;语法简单，学习曲线低&lt;/li&gt;
&lt;li&gt;代码简洁，格式统一&lt;/li&gt;
&lt;li&gt;静态类型，编译期检查&lt;/li&gt;
&lt;li&gt;内置GC，Runtime期识别&lt;/li&gt;
&lt;li&gt;标准库丰富，网络库简单易用&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;运行性能

&lt;ul&gt;
&lt;li&gt;编译为机器码，不依赖其它库&lt;/li&gt;
&lt;li&gt;语言层面并发模型，可充分利用多核&lt;/li&gt;
&lt;li&gt;内嵌C支持，可直接利用C的资产&lt;/li&gt;
&lt;li&gt;启动快，执行效率高，内存占用低&lt;/li&gt;
&lt;li&gt;标准库质量高，针对性优化&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;维护成本

&lt;ul&gt;
&lt;li&gt;没有什么语法糖，高级特性少，格式统一，阅读方便&lt;/li&gt;
&lt;li&gt;自带工具链完善，如代码格式化，代码检查，性能分析等工具&lt;/li&gt;
&lt;li&gt;默认编译为单个执行文件，部署简单，超赞&lt;/li&gt;
&lt;li&gt;标准库跨平台支持，迁移成本非常低&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;不足&#34;&gt;不足&lt;/h3&gt;

&lt;p&gt;当然Go在工程方面也不是很完美，就目前个人使用经验来看：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;缺少Go工程的依赖库版本管理，尤其是使用第三方开源不好控制（注：1.5引入 go vendor）&lt;/li&gt;
&lt;li&gt;错误机制采用返回值，真是满眼的if来判断错误，代码相似度高&lt;/li&gt;
&lt;li&gt;接口与实现未分离，对于商用产品，想只提供接口定义来保护知识产权操作不方便&lt;/li&gt;
&lt;li&gt;Goroutine调度切换不能由程序控制，需由上层有严谨的设计，维护困难，容易修改出问题&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;如果你也是在云计算领域，或会从事服务端的应用开发，如中间件，分布式，网络通讯的系统开发，有时间不妨学习学习Go，他简单易学，多掌握一语言，多一门求生技能。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>配置与定制</title>
      <link>http://lanlingzi.cn/post/technical/2015/0813_cfg_vs_cus/</link>
      <pubDate>Thu, 13 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2015/0813_cfg_vs_cus/</guid>
      <description>&lt;p&gt;作为一个软件人员，我们会经常遇到各种各样的需求，有时为了避免定制，通常的做法是提供更多的配置选项，以通过配置出满足不同的特定需求。&lt;/p&gt;

&lt;p&gt;原因是而当你开发定制代码来修改或扩展一个功能需求时，有可能会导致软件不能正常的工作，必须通过严格的测试与验证。在重大的版本升级情况下，定制是苛刻的和耗时的。甚至会面临无法修复的功能可能会被重构，从零开始。因此，一些做法是通过采越来越多地选择配置，来解决由于开发定制代码引入的问题与软件带来的成本。&lt;/p&gt;

&lt;p&gt;因此配置与定制之间的区别是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;配置：使用现有的数据来配置系统以满足您的业务需求&lt;/li&gt;
&lt;li&gt;定制：将定制或使系统适应业务需求，涉及到定制开发流程。
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;作为一名开发或设计人员，重要的是要了解不同的配置和定制的区别，差异的关键是复杂度。配置使用的软件具有固有的灵活性，如添加字段，更改字段名称，修改下拉列表，或添加按钮。配置是使用强大的内置功能集。而定制是包括代码更改以创建出不可通过配置解决的功能。定制可能是昂贵的，并且可能会使软件的升级复杂化，因为由于代码变更可能不会很容易迁移到新版本。像“修改”或“扩展”往往意味着不同的东西，存在不确认的风险。&lt;/p&gt;

&lt;p&gt;要避免定制，提供的一些配置工具并不总是一个较简单的选择。但这些配置选项如何配合业务运行时，也会让运维人员无所事从，太多的配置选项最终变成谁也不敢去使用，因为无法去评估配置带来的运行期的影响。一种方式是提供向导驱动的配置，但同样面临没有在初始部署时掌握他们的细节和晦涩深奥的设置。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>微服务与SOA</title>
      <link>http://lanlingzi.cn/post/technical/2015/0516_microservice_soa/</link>
      <pubDate>Sat, 16 May 2015 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2015/0516_microservice_soa/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://martinfowler.com/articles/microservices/images/sketch.png&#34; alt=&#34;microservices&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我司学习一个新的技术，往往是搞得轰轰烈烈，比如数字化转型，向互联网技术学习。其中一个非常重要的方向就是学习互联网的服务化体系架构。国内的阿里，京东，腾讯在服务化，确切地说是微服务应用取得非常大的成功。而国外的Netflix的微服务架构更是成为我们必定的样板教材。你做设计，谈方案，不说说微服务都不好意思。如果你不说这样，说明你思维落后陈旧了。任何一项技术都有一段疯狂期，虽这近一次在搞架构重构，领导遇到你，总是关心地问到：“服务化进展怎么样了”。甚至还得跟一些不太懂的领导解释什么是微服务。&lt;/p&gt;

&lt;p&gt;10年前差不到了SOA也像今天的微服务一样火爆。那微服务与SOA的关系或区别是什么？是不是SOA的旧洒换新瓶？软件界的大牛 Martinfowler的《&lt;a href=&#34;http://martinfowler.com/articles/microservices.html&#34;&gt;微服务&lt;/a&gt;》更是像一部微服务的圣经，无奈是E文，大家都有各自的理解。在我司更是大家对这个各抒己见，谁都可以说上几句服务化的原则是什么，微服务成了领导专家们口里的口头禅。如果我们的系统不是微服务化，都怀疑我们系统的先进性。想当初，大家也都谈SOA，也极力推广SOA。似乎到了今天，微服务与SOA两者是势不相容。SOA是传统的IT架构，而微服务是当今互联网架构，微服务似乎比SOA更“逼格”。甚至这样的争论成了不同兄弟的心头痛。
&lt;/p&gt;

&lt;p&gt;那先来看看Martinfowler怎么说的：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;微服务风格也与SOA所提倡的一些优势非常相似。尽管如此，问题在于SOA意味的太多&lt;a href=&#34;http://martinfowler.com/bliki/ServiceOrientedAmbiguity.html&#34;&gt;不同的东西&lt;/a&gt;了，因此通常时候我们谈的所谓“SOA”时，它与我们谈论的风格不一致，因为它通常是指在整体风格应用中的ESB。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;从试图使用ESB隐藏复杂性，到集中治理模式抑制变更，这种面向服务的风格是复杂的，没有ESB什么都不是。互联网的发展，利用简单的协议方法，让它从这些经验传达的出来。可能说对SOA集中式标准中的一种反模式，而SOA需要用一个服务来管理你的所有的服务，你就知道这很麻烦。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;SOA的这种常见行为让微服务的提倡者拒绝打上SOA的标签，尽管有人认为微服务是从SOA中发展而来的，或许面向服务是对的。无论如何，事实上SOA表达这么多的含义，它给一个团队清醒的认识到这种构架风格就已经值的了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;至少Martinfowler在面向服务体系中，微服务是从SOA发展出来的，只是大家受到SOA的伤害而不太愿意打上SOA的标签。他们本质与出发点是相同的。微服务是细粒度的SOA，你不用去关心“庞大的”ESB，也不用去熟悉大堆的WS-*术语。当服务变得微小（micro）时，服务可能是由规模恰当的团队（12个人）制定的，也可能是单个人制定的。&lt;/p&gt;

&lt;p&gt;我们没有办法对微服务进行准确的定义，怎么去划分服务，什么算是微服务？两个比萨能吃饱的团队（12个人）也说得太抽象了，在面对具体的实践来说，到底怎么才是SOA中微小服务，我们又如何去分析与设计？以为团队中的成员能力来划分，学是以业务功能集来划分，再去组织团队？这些问题都是我们在实践中面对的挑战。&lt;/p&gt;

&lt;p&gt;微服务架构中的“微”体现了其核心要素，即服务的微型化，就是每个服务微小到只需专注做好一件事。 这件事紧密围绕业务领域，形成高度内聚的自治性。&lt;/p&gt;

&lt;p&gt;微服务架构强调“微”，与之前有些采用了SOA服务化架构思想的系统搞出很多胖服务来说，一点也不微，这依然带来耦合。 这一点只能依赖系统架构师的服务化建模能力了，但微服务架构强调每个服务一个进程， 使用进程为边界来隔离代码库至少让同一应用系统不同层次的开发人员享有自己完全自治的领地，每个微服务都有一个掌控者。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://book.douban.com/subject/25881698/&#34;&gt;《Building Microservices》&lt;/a&gt;一书对实施微服务架构有系统性的描述和很多业界案例的简单引用描述，这里不展开讲实施细节，那样就太长了。简单总结下实施的要点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;自动化文化与环境：自动构建、自动测试、自动部署。&lt;/li&gt;
&lt;li&gt;围绕业务能力建模服务，松耦合、高内聚、暴露接口而隐藏实现细节。&lt;/li&gt;
&lt;li&gt;服务协作模型：中心化（乐队模型：中心指挥）和去中心化（舞蹈模型：群舞自组织），各自场景不同。&lt;/li&gt;
&lt;li&gt;服务交互方式：RPC/REST/WS 技术很多但考虑统一。&lt;/li&gt;
&lt;li&gt;服务部署：独立性、失败隔离性、可监控性。&lt;/li&gt;
&lt;li&gt;服务流控：降级、限流&lt;/li&gt;
&lt;li&gt;服务恢复：多考虑故障发生如何快速恢复而非如何避免发生故障。&lt;/li&gt;
&lt;li&gt;服务发布：灰度。&lt;/li&gt;
&lt;li&gt;服务部署：一服务一主机模型，需要虚拟化(Hypervisor)、容器化(LXC, Docker)等技术支持，实现硬件资源隔离。&lt;/li&gt;
&lt;li&gt;服务配置：中心化配置服务支持&lt;/li&gt;
&lt;li&gt;康威定律：任何设计系统的组织，最终产生的设计等同于组织之内、之间的沟通结构。系统架构的设计符合组织沟通结构取得的收益最大。&lt;/li&gt;
&lt;li&gt;伯斯塔尔法则：服务健壮性原则 —— 发送时要保守，接收时要开放。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;注：部分参考 &lt;a href=&#34;http://mindwind.me/blog/2015/05/14/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%AE%9E%E8%B7%B5%E6%84%9F%E6%82%9F.html&#34;&gt;《微服务架构实践感悟》&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>架构重构</title>
      <link>http://lanlingzi.cn/post/technical/2015/0430_arch_refactor/</link>
      <pubDate>Tue, 12 May 2015 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2015/0430_arch_refactor/</guid>
      <description>&lt;p&gt;最近一直在做系统架构上重构工作，理论不能不学习啊，只有在思想上把自己武装起来，才能减少我们工作上的错误。之前参加过或亲自操刀过多次的代码局部或模块重构，但这一次架构重构是范围波及最广，收获颇多。&lt;/p&gt;

&lt;h2 id=&#34;什么是重构&#34;&gt;什么是重构&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;重构是指在不修改代码外在行为的前提下，对代码做出的修改，以改进程序的内部结构，提高其可理解性，降低其修改成本。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这是来自马大神的《重构》一书对重构释义。重构可以改进软件设计；使软件更容易理解；使软件更容易维护；帮助找到软件Bugs；帮助提高编程效率。重构按对系统修改的粒度层次可以分为如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;局部代码重构，操作与实施比较容易，《重构》一书中介绍了大量经典的方法。&lt;/li&gt;
&lt;li&gt;模块级代码重构，可能涉及到模块之间的接口重构，操作与实施难度相对适中。&lt;/li&gt;
&lt;li&gt;架构重构，是对整个系统架构层次的重构，牵系相当的广，操作与实施难度比较高。
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;重构风险&#34;&gt;重构风险&lt;/h2&gt;

&lt;p&gt;无论何种层次的重构，都必须要有一个可靠的测试环境，即自动化测试环境。因为频繁的代码修改可能会引入更多的缺陷，只有执行自动化测试并回归所有用例，才能保证及时发现这些缺陷，最大限度地降低重构的风险。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;局部的不良代码，可以通过小范围的重构来优化。但是对于架构上重构，因为重构影响范围过大，在实践中仍然存在绪多的困难。&lt;/li&gt;
&lt;li&gt;架构上大的重构，至少几十人的投入，更需要半年到一年的开发周期。在老软件不能停止维护的前提下，这对开发人力将产生巨大冲击。&lt;/li&gt;
&lt;li&gt;新架构虽然先进，但历史经验表明，新软件的成熟与稳定需要时间。在沉重的交付压力下，风险需要做很多的预防控制。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;为什么要重构&#34;&gt;为什么要重构&lt;/h2&gt;

&lt;p&gt;给老大说明重构的意义往往很难，尤其不是技术出身的管理者，即使是，也需要面临交付上的考虑。从技术上讲，为什么要重构：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不论如何先进的软件架构也不可能预见到几年甚至十几年后的需求，并预先设计&lt;/li&gt;
&lt;li&gt;随着新功能的不断增加，以及新成员的加入，软件架构必然逐渐腐化&lt;/li&gt;
&lt;li&gt;虽然强力的架构看护制度可以延缓架构腐化的速度，但不可能看护到实现细节&lt;/li&gt;
&lt;li&gt;重构则提供了软件持续优化的机会，从而使软件更容易适应新的需求，同时及时地改进不合理的部分&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;重构与重写&#34;&gt;重构与重写&lt;/h2&gt;

&lt;p&gt;对于一次重构来说区别不大，只是力度不同，重构侧得局部优化，也会重用现有的资产，重构的极端就是重写。他们的主要区别是重构强调的是持续的，随时的优化，而重写强调的是一次性的天翻地覆的改造。那我们如何判断是要重构还是重写？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;重构是持续的，并不是等到极端恶心才开始优化，所以坚持持续的重构可以代价更小的达到优化的目的&lt;/li&gt;
&lt;li&gt;若已经极端恶化的模块，重写也是一种解决方式，但要注意避免失控，须在设计、测试、管理、人员能力等多方面要做好准备&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;何时重构&#34;&gt;何时重构&lt;/h2&gt;

&lt;p&gt;何时重构，因项目因人员能力而异：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不同粒度层次的重构，重构的时机选择应该是不同的&lt;/li&gt;
&lt;li&gt;不同粒度层次的重构，实施的节奏也必然不同的&lt;/li&gt;
&lt;li&gt;关键技术需要提前原型验证，风险评估&lt;/li&gt;
&lt;li&gt;对于模块级，架构级重构，通常在添加新功能或特性之前充分考虑，留出部分空档期来重构&lt;/li&gt;
&lt;li&gt;制定重构计划，步步为营，切忌全面开花，导致风险不可控&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;同时在重构时，需要平衡重构与交付：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;为了交付而不重构，是恶性循环，最终交付的压力会越来越大，质量会越来越差&lt;/li&gt;
&lt;li&gt;对于模块级，架构级重构，应该是有计划地落入到迭代版本中&lt;/li&gt;
&lt;li&gt;可以采用冬虫夏草的方式重构，逐步重构或替换，随时（至少每个迭代）可以保证系统的完整性&lt;/li&gt;
&lt;li&gt;注意控制每次迭代重构的范围，要分析并划分合理的重构边界&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;重构人员&#34;&gt;重构人员&lt;/h2&gt;

&lt;p&gt;重构最终落实还是人员能力，对于参与的人员能力要求：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;知道重构的意义，重构需要有个人强烈的意愿，才能有所突破&lt;/li&gt;
&lt;li&gt;对现有的组件流程与实现非常地清楚&lt;/li&gt;
&lt;li&gt;针对性强，能够熟练地运用各种重构方法&lt;/li&gt;
&lt;li&gt;能够察觉出实现的问题，能提出改进（重构）建议（方案）&lt;/li&gt;
&lt;li&gt;经验是基础，对构架本身的体系有较为深厚的理解和应用经验&lt;/li&gt;
&lt;li&gt;不同层级的重构，需要不同的参与，不同阶段投入&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;重构中有哪些角色，他们职责是什么&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SA/SE（系统架构师，系统设计师）：负责按照架构正确地设计与分解需求，能清楚系统中的痛点，以及各组件的主要问题&lt;/li&gt;
&lt;li&gt;SE/MDE（系统设计师，模块设计师）：负责某个组件整体看护，设计组件内疗实现机制，系统约束等&lt;/li&gt;
&lt;li&gt;SWE（软件工程师）：在软件架构的基础上，负责具体的功能实现。&lt;/li&gt;
&lt;li&gt;TE（测试工作师）：补充用例，执行自动化测试，及时发现系统中的缺陷，并与SWE结队处理问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;总之，重构要务实，务实就是尊重现实，基于现实情况分析与实施，不断地推进演化。架构重构不仅需要充分的设计，切实有效的重构操作方法也非常地重要。架构重构，抛开代码搞理论上的重构不行；充分利用代码，但又不能掉进“代码泥潭”。无论怎么重构，一定要构建夯实的测试防火墙，快速反馈重构中的问题。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OSGi的缘起缘灭</title>
      <link>http://lanlingzi.cn/post/technical/2015/0422_remove_osgi/</link>
      <pubDate>Wed, 22 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/technical/2015/0422_remove_osgi/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://www.osgi.org/wp-content/uploads/bigpuzzle.jpg&#34; alt=&#34;osgi&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;什么是osgi&#34;&gt;什么是OSGi&lt;/h2&gt;

&lt;p&gt;维基百科：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;OSGi（Open Service Gateway Initiative）有双重含义。一方面它指OSGi Alliance组织；另一方面指该组织制定的一个基于Java语言的服务（业务）规范——OSGi服务平台（Service Platform）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们所说的OGSi，通常讲的是Java语言实现的OSGi，但也是有其它语言实现过OSGi，由于没有Killer应用，几乎是无人知晓。&lt;/p&gt;

&lt;p&gt;2003年Eclipse选择OSGi作为其插件的底层运行时架构。Equinox project对该理念进行了实验，2004年6月在Eclipse3 R3中发布。Eclipse的成功让人认识到OSGi的优秀与魅力，也把OSGi带到众多的程序员面前。
&lt;/p&gt;

&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;

&lt;p&gt;正好10年底开始转型做云计算，当时选型的开发语言是Java，这没有错，看看目前Java在云计算中应用程度，说明我们是选对了。同时我们也选型开发框架。我当时受到Eclipse的基于OSGi的插件机制成功影响，是极力推荐使用OSGi的。当然最终决策采用OSGi的不是我，但我的确在其中起了摧动作用。当时采用它的主要原因我想有如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;模块化，模块之间基于服务接口通讯。&lt;/li&gt;
&lt;li&gt;插件化，Bunlde可以动态加载。&lt;/li&gt;
&lt;li&gt;组件化，面向服务的组件，组件由多个服务组成。&lt;/li&gt;
&lt;li&gt;生命周期管理，相比普通Jar包，我们可以更细粒度的管理&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们使用OSGi，采用两种框架，一个是Apache的Felix，使用它主要是看重它很小，用于开发主机代理，在其上开发各种采集插件。一个是Spring的Spring DM，即后面的Eclipse Virgo。使用它主要是看重它集成了Spring，用于开发后端服务，采用Spring DM来简化OSGi的服务发布与引用，以及能较好地使用Spring的其它能力。&lt;/p&gt;

&lt;p&gt;可以说从11年到14年，我都是在基于OSGi做开发，从早期喜爱到最后的放弃，个中的滋味真不知怎么说。期间我在整个团队做了不少关于OSGi的推广，写过些文档介绍，规范要求，定位过稀奇的问题，最后大家都觉得我是这一方面的专家，只有搞不定的问题就来找我，我才逐渐意识到OSGi的理念虽好，但要真的把它使用得很好，真是不简单啊。&lt;/p&gt;

&lt;p&gt;OSGi虽解决了本地的服务访问的问题，但云系统是一个分布式的系统，所以在后面又折腾过DOSGi，使用是的CXF实现的DOSGi，这个更难使用。先只有少数一两个服务在尝试使用它，期间遇到的问题更多，最后也不得不在13年初就放弃了。我不得不搞出另一个RPC的框架出来。&lt;/p&gt;

&lt;h2 id=&#34;缘灭&#34;&gt;缘灭&lt;/h2&gt;

&lt;p&gt;在去年的时候就开始讨论是否去OSGi，连最早鼓吹使用OSGi的阿里，也花了很大精力去OSGi，不过他们的动作早在12年就开始了，Spring也在12年摒弃OSGi，把Spring DM捐献给Eclipse。我们更是受项目进度与人力不足限制，去OSGi也只是停留在讨论中，有点&lt;code&gt;“不破不修”&lt;/code&gt;的意思，OSGi凑合着使用。&lt;/p&gt;

&lt;p&gt;15年软件界最火爆的两个词可能是：&lt;code&gt;微服务&lt;/code&gt;，&lt;code&gt;Docker&lt;/code&gt;。去年平台定位发生变化，从偏IaaS转型偏应用的PaaS，原有的架构存在些问题；而今年的&lt;code&gt;微服务&lt;/code&gt;概念也直接点然了系统架构重构的火把，而我又是这次架构重构实施落地的组长。这真是有点戏剧性啊！&lt;code&gt;“出来混迟早要还的”&lt;/code&gt;，当初我是团队中使用OSGi的带头人，今天又是团队中OSGi的埋葬人。老大们要求我们把架构重构，目标是系统解耦合，轻量化，利于团队分工。自然去掉OSGi，朝分布式微服务化演进在设计考虑的范围中。的确，微服务化与OSGi也不冲突，为什么要去OSGi呢：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OSGi的门槛太高，学好用好它对程序员要求高，而团队新人比例高&lt;/li&gt;
&lt;li&gt;很多第三方组件不是Bundle，需要Bundle化，增加维护成本&lt;/li&gt;
&lt;li&gt;使用到其它部门的中间件也宣称不支持OSGi，越来越处于孤立&lt;/li&gt;
&lt;li&gt;多版本管理问题，在同一套环境中，相同的第三方Jar存在多个版本，版本无法归一，增加维护成本&lt;/li&gt;
&lt;li&gt;基于OSGi的服务接口测试难度高，LLT测试时依赖于OSGi环境，测试成本高&lt;/li&gt;
&lt;li&gt;OSGi的服务接口只是本地接口，而云计算中恰恰需要分布式服务调用框架&lt;/li&gt;
&lt;li&gt;ClassLoder问题，导致很多的开发兄弟考虑不足出问题，经常是运行期抛ClassNotFound&lt;/li&gt;
&lt;li&gt;Virgo， Felix其实也很重，多个组件部署在同一套环境中，隔离性差，不适合微服务理念&lt;/li&gt;
&lt;li&gt;Bundle的动态替换就是伪命题，从来没有用过&lt;/li&gt;
&lt;li&gt;用于做插件机制，动态加载的ClassLoder问题&lt;/li&gt;
&lt;li&gt;JRE在Virgo环境下会出现死锁，需要升级JRE到8才能解决，还不知会有其它问题，社区支持不足&lt;/li&gt;
&lt;li&gt;大环境下，OSGi已成明日黄华，不再是宠儿&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从上面可以看出，OSGi的面向接口编程，服务化，模块化理念在单体应用来说虽不错，在面对分布式的应用时，它带的益处远比它的本身的机制带的问题更多。所以OSGi留得越久，越是技术债务，早去掉早解脱啊。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>软件开发中缺陷管理</title>
      <link>http://lanlingzi.cn/post/thoughts/2014/0901_soft_dev_dt_trace/</link>
      <pubDate>Mon, 01 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/thoughts/2014/0901_soft_dev_dt_trace/</guid>
      <description>&lt;p&gt;在我司，我发现大家很擅长把一个东西到极致，但极致可能是过犹不及了，例如测试并不是发现越来越多的Bug就越好，如果把很多的时间消耗到一些不重要的点，反而不可取，软件只要你去测试，怎能发现一些Bug，如要面对这些就非常纠结。作一名开发，说这话肯定会被一批的测试人员拍砖死了。在此表达一下不同的观点，不一定正确，请轻拍。&lt;/p&gt;

&lt;p&gt;在我司的各种度量工具很牛X，缺陷跟踪分析每个迭代阶段就会做，形成一些报告。对于软件质量来说，统计所有过去的Bugs是没有多大用的，相对来说，一些更实际的工作可能更重要，在Douglas Hubbard的《How to Measure Anything: Finding the Value of Intangibles in Business》(如何衡量任何事：寻找商业无形资产的价值)中，把这种现象解释成衡量倒置(Measurement Inversion)：衡量一个东西的经济价值与它通常所受到的关注度多少成反比。
&lt;/p&gt;

&lt;p&gt;一种较有说服力的观点是缺陷跟踪方便人们发现缺陷的趋势，对流程的改变很有一些效果，如提前做些缺陷预防。对于管理者来说，他们需要缺陷跟踪报告可能了解软件的质量状况。但可能实际却不是这样的，单单根据DI值来判断软件质量，这跟由湿度来判断天气是否好坏一样不太靠谱。&lt;/p&gt;

&lt;p&gt;质量是什么，尤其是软件的质量是什么？是看软件的缺陷率吗？比如我现在比较喜欢荣耀手机，我会关注荣耀手机DTS中的单有多少吗？在消费者的眼中，质量就是对他有价值的东西。如果客户是快乐的，存在一些漏洞也是问题不大的。如果客户抱怨，跟有多少Bugs是无关的。&lt;/p&gt;

&lt;p&gt;前几年在摧广敏捷时，提到做刚刚好的系统，也提到了零缺陷：符合已确定之要求，一次做对。第一次把正确的事情做正确，包含了三个层次：正确的事、正确地做事和第一次做正确，三个因素缺一不可：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;正确的事：辨认出客户的真正需求，从而制定出相应的战略。&lt;/li&gt;
&lt;li&gt;正确地做事：软件开发中所必需的全部活动都符合客户和市场的客观要求。&lt;/li&gt;
&lt;li&gt;第一次做正确：防止不符合要求的成本产生，从而降低质量成本，提高效率。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;什么是软件的缺陷，在软件程序中存在任何一种破坏正常运行能力的问题，都可能叫作缺陷，Bugs。但生产软件的最终目的是为了满足客户需求，如果以客户需求作为判断软件质量的标准，软件的缺陷可以包括如下几个因素：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;软件未达到客户需求的功能与性能要求；&lt;/li&gt;
&lt;li&gt;软件出现客户需求不能容忍的错误；&lt;/li&gt;
&lt;li&gt;软件的使用未能符合客户的习惯或工作环境。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;软件测试其实并不只是要发现问题，如果我们进行非常变态的测试，的的确确能发现很多的问题，但是有可能此类问题根本不可能出现，或是在软件生命周期内也永远不会出现，没有这么复杂的使用场景。在做异常测试，虽然一定要以发现缺陷的心态挖掘测试，但也不应该是一种无所欲为的测试。还好，公司已积累了不少的故障模式库供参考分析。但是像可服务性，可维护性，易用性应该做到什么样的程度却在实际项目操作中很难把握。任何缺陷的修改都是有成本的，一旦控制不好，可能把有限的精力都浪费在不重要的点了，这也是开篇所说的过犹不及。&lt;/p&gt;

&lt;p&gt;测试人员认为某种情况是缺陷，但开发人员认为又不是，而现实就是所争议的情形在需求中也没有明确地描述。公说公有理，婆说婆有理，说不清，道不明的。开发与测试的争执由此开始，矛盾也由此产生，不和谐的气氛由此理下种子。出的原因可能有多种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;需求澄清不清，需求描述太过于简单，离最终的客户又远。&lt;/li&gt;
&lt;li&gt;对于原始需求没有进行评审，整理，并书面化归档。其实需求文档也要测试验证的。&lt;/li&gt;
&lt;li&gt;开发与测试存在理解上的偏差；&lt;/li&gt;
&lt;li&gt;需求本身的定义存在二义性。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;面对这种问题，无论开发与测试人员需要知道：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;要知道任何的争论解决不了问题，争论不要存在个人感情色彩(其实这个很难做到)；&lt;/li&gt;
&lt;li&gt;出现问题，首先从自身找问题，有时往往是因为我们的简单思维导致。&lt;/li&gt;
&lt;li&gt;人非圣贤，有错就改，并不失面子。讨论对事不对人。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可能在很多的部门，把缺陷做为开发或测试的绩效指标，这种简单而粗暴管理，直接的结果就是让开发和测试从此不和谐，彼此斗角。要相信办法总是比问题多，每一个问题都有至少一个解决的办法，愿开发与测试都能朝同一个目标，把软件做到刚刚好，事成人爽。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>软件开发与中医理论</title>
      <link>http://lanlingzi.cn/post/thoughts/2014/0804_soft_dev_tcm_theory/</link>
      <pubDate>Mon, 04 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>http://lanlingzi.cn/post/thoughts/2014/0804_soft_dev_tcm_theory/</guid>
      <description>&lt;p&gt;最近一段时间，看了些的版本迭代开发数据。有CI中QDI，FindBugs，重复率，复杂圈度；也有迭代的Story实现率，IR分解率，DI值;也有测试用例，覆盖率，执行时长，入门用例比等。反正各种度量数据多得是，从各个方面来反馈项目的质量。俗话说：有人的地方就有江湖。有江湖的地方就有纷争。有度量数据就有晒马排名，有排名的地方就有政治任务。我们的流程辅助度量工具多了，但这些真能带动我们的质量上去了吗？&lt;/p&gt;

&lt;p&gt;小儿已一岁多，现在回顾他做的一些体检。前三个月每月一次体检，一岁之前每3个月一次，一岁之后是每6个月一次。体检的项目有称体重、量身高、量头围、量胸围、验视力、测听力、检查动作发育、口腔检查、评价智能发育、验血、骨骼检查、心肺与心率检查、大便和血红蛋白。体检医生一上来就是开各个体检单，采用是西医的方式，看指标数据，再评测，体检应该是医院最好的生财路之一。个人也明白，正如我妈说的，我小时候哪有什么体检，也不是好好的吗？现在带小孩去体检，也是图个安心，提早预防。

那说这些跟软件开发有什么关系？西医是基于实验科学，从实验走向临床，再到应用，它关注对外界变化的认知，比如发现了细菌，就有了抗生素；发现了病毒，就有了疫苗；发明了人工心脏，就可以做植入心脏。西医的研究对象是外界。&lt;strong&gt;强调对症下药，看的是病&lt;/strong&gt;。而中医以阴阳五行为基础，将人体看到气，形，神的统一。聚焦于人本身，就是人的经络，阴阳，五行等。通过中药、针灸、推拿、按摩、食疗、拔罐等多种手段来达到人体的阴阳调和而康复。&lt;strong&gt;强调调和平衡，看的是人&lt;/strong&gt;。西医通过相同的病因数据，药物使用可能复制到不同的人。而中医需要通过医生的非常经验，开出不同的药方。所以年纪越老的中医越是历害。&lt;/p&gt;

&lt;p&gt;现在的软件工程，也似乎像西医一样，试图通过固化流程，工程手段，指标数据来统一所有项目的开发。典型的是CMM，它关注项目本身，往往忽略了项目中的人。一个C版本三个月，我们个人并没有在这短短的三个月里边发生什么实质性的变化。一个本来连计划变更都要审批，还要被QA严格审计的受控团队，有时又变成一个居然可以什么都自己估算，和中途临时领取需求任务的自组织的团队，不可不谓一个相当疯狂的举动。最后项目管控就看是各种指标数据，个中变化指标能看到什么呢？即使各种指标细化，能真实的反应项目的实情吗，这要大大地打个问号了。也有人会说，数据好的项目并不一定好，但数据差的项目一定是不好。好吧，我认这一条。&lt;/p&gt;

&lt;p&gt;外界的敏捷开发，应该是强调项目中人的本身吧，快速适合各种变化。管理以人为本，时刻进行相应的调整，尽可能地发挥个体的能力。一个被各种指标数据盯着的团队能放下这些，快速适合变化，快速响应客户的需求吗？软件的开发过程也不可能固定不变，因人而异，因项目而异，一两种软件工程学能搞定所有的项目吗？&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>